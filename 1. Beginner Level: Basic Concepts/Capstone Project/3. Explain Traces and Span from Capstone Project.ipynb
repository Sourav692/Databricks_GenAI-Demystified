{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d9c91c2-c89c-4b26-9669-ab5a2d0b18e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Mastering MLflow Tracing: Understanding Traces and Spans for Production AI Agents\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Building AI agents is exciting, but deploying them to production is where the real challenge begins. How do you know what your agent is doing internally? Where is it spending time? Why did it fail? What tools did it call and with what parameters?\n",
    "\n",
    "This is where **MLflow Tracing** comes in‚Äîa powerful observability framework that transforms your AI agent from a mysterious black box into a transparent, debuggable, and optimizable system.\n",
    "\n",
    "In this comprehensive guide, we'll explore traces and spans using a real-world tool-calling agent built with LangGraph and MLflow. We'll demystify these concepts with practical examples and show you exactly how they work under the hood.\n",
    "\n",
    "## What is Observability in AI Agents?\n",
    "\n",
    "Before diving into traces and spans, let's understand why observability matters.\n",
    "\n",
    "Imagine you've deployed an AI agent that helps users with product queries. One day, users report slow responses. Without observability, you're left guessing:\n",
    "\n",
    "- Is the LLM slow?\n",
    "- Are the tools taking too long?\n",
    "- Is there a network issue?\n",
    "- Did the agent make unnecessary calls?\n",
    "\n",
    "With MLflow tracing, you can see exactly what happened, step by step, call by call.\n",
    "\n",
    "## Understanding Traces\n",
    "\n",
    "### What is a Trace?\n",
    "\n",
    "A **trace** represents the complete execution flow of a single request through your agent system. Think of it as a detailed journey map from the moment a user asks a question until they receive an answer.\n",
    "\n",
    "### Trace Components\n",
    "\n",
    "Every MLflow trace consists of two primary components:\n",
    "\n",
    "#### 1. **TraceInfo** - The Metadata Container\n",
    "\n",
    "TraceInfo provides a high-level overview of the trace:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"trace_id\": \"tr_abc123xyz\",\n",
    "    \"request_time\": 1732315680000,\n",
    "    \"execution_duration\": 8450,  # milliseconds\n",
    "    \"state\": \"OK\",  # OK, ERROR, IN_PROGRESS\n",
    "    \"request_preview\": \"What is the latest news on OpenAI product releases?\",\n",
    "    \"response_preview\": \"Here are the latest OpenAI developments...\",\n",
    "    \"tags\": {\n",
    "        \"use_case\": \"analytics\",\n",
    "        \"user_id\": \"user_789\",\n",
    "        \"session_id\": \"session_456\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Key Fields:**\n",
    "- `trace_id`: Unique identifier for the trace\n",
    "- `execution_duration`: Total time taken (in milliseconds)\n",
    "- `state`: Success or failure status\n",
    "- `tags`: Searchable metadata for filtering and grouping\n",
    "\n",
    "#### 2. **TraceData** - The Execution Details\n",
    "\n",
    "TraceData contains the actual execution information organized as spans:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"spans\": [\n",
    "        # Root span\n",
    "        {\"span_id\": \"sp_001\", \"name\": \"agent_execution\", ...},\n",
    "        # Child spans\n",
    "        {\"span_id\": \"sp_002\", \"name\": \"llm_call\", \"parent_span_id\": \"sp_001\", ...},\n",
    "        {\"span_id\": \"sp_003\", \"name\": \"tool_execution\", \"parent_span_id\": \"sp_001\", ...},\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "## Understanding Spans\n",
    "\n",
    "### What is a Span?\n",
    "\n",
    "A **span** represents a single unit of work within a trace. Spans form a hierarchical tree structure where each span can have child spans, creating a detailed execution timeline.\n",
    "\n",
    "### Span Anatomy\n",
    "\n",
    "Each span captures rich information about a specific operation:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"span_id\": \"sp_002\",\n",
    "    \"parent_span_id\": \"sp_001\",\n",
    "    \"name\": \"llm_call\",\n",
    "    \"span_type\": \"LLM\",\n",
    "    \"start_time\": 1732315680150,\n",
    "    \"end_time\": 1732315682800,\n",
    "    \"inputs\": {\n",
    "        \"messages\": [...],\n",
    "        \"model\": \"databricks-meta-llama-3-3-70b-instruct\",\n",
    "        \"temperature\": 0.01\n",
    "    },\n",
    "    \"outputs\": {\n",
    "        \"content\": \"...\",\n",
    "        \"tool_calls\": [...]\n",
    "    },\n",
    "    \"attributes\": {\n",
    "        \"mlflow.chat.tokenUsage\": {\n",
    "            \"input_tokens\": 67,\n",
    "            \"output_tokens\": 45,\n",
    "            \"total_tokens\": 112\n",
    "        },\n",
    "        \"execution_time_ms\": 2650\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### Span Types in MLflow\n",
    "\n",
    "MLflow defines several span types for different operations:\n",
    "\n",
    "- **AGENT**: Agent-level orchestration\n",
    "- **CHAIN**: Workflow or chain execution\n",
    "- **LLM**: Language model calls\n",
    "- **TOOL**: Tool or function execution\n",
    "- **RETRIEVER**: Document retrieval operations\n",
    "- **PARSER**: Output parsing operations\n",
    "\n",
    "## Real-World Example: Tool-Calling Agent\n",
    "\n",
    "Let's build a practical agent and see how traces and spans work in action. We'll use the code from the GitHub repository.\n",
    "\n",
    "### The Agent Architecture\n",
    "\n",
    "Here's our MLflow-compatible tool-calling agent:\n",
    "\n",
    "```python\n",
    "from typing import Annotated, Optional, Any\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from databricks_langchain.uc_ai import (\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langgraph.prebuilt.tool_node import tools_condition\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import ChatAgentMessage, ChatAgentResponse, ChatContext\n",
    "from mlflow.models import ModelConfig\n",
    "\n",
    "def create_tool_calling_agent(model, tools):\n",
    "    \"\"\"\n",
    "    Create a tool-calling agent with MLflow tracing support\n",
    "    \"\"\"\n",
    "    llm_with_tools = model.bind_tools(tools=tools)\n",
    "    \n",
    "    # Preprocessor extracts messages from state\n",
    "    preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n",
    "    model_runnable = preprocessor | llm_with_tools\n",
    "\n",
    "    def tool_calling_llm(state: ChatAgentState, config: RunnableConfig):\n",
    "        \"\"\"\n",
    "        LLM node that processes messages and decides whether to call tools\n",
    "        This function is automatically traced by MLflow\n",
    "        \"\"\"\n",
    "        response = model_runnable.invoke(state, config)\n",
    "        return {\"messages\": [response]}\n",
    "    \n",
    "    # Build the graph\n",
    "    builder = StateGraph(ChatAgentState)\n",
    "    builder.add_node(\"tool_calling_llm\", RunnableLambda(tool_calling_llm))\n",
    "    builder.add_node(\"tools\", ChatAgentToolNode(tools=tools))\n",
    "    builder.add_edge(START, \"tool_calling_llm\")\n",
    "    \n",
    "    # Conditional routing based on tool calls\n",
    "    builder.add_conditional_edges(\n",
    "        \"tool_calling_llm\",\n",
    "        tools_condition,  # Routes to tools or END\n",
    "        [\"tools\", END]\n",
    "    )\n",
    "    builder.add_edge(\"tools\", \"tool_calling_llm\")  # Feedback loop\n",
    "    \n",
    "    return builder.compile()\n",
    "```\n",
    "\n",
    "### The MLflow-Compatible Agent Class\n",
    "\n",
    "```python\n",
    "class DocsAgent(ChatAgent):\n",
    "    def __init__(self, config, tools):\n",
    "        \"\"\"\n",
    "        Initialize agent with configuration and tools\n",
    "        \"\"\"\n",
    "        self.config = ModelConfig(development_config=config)\n",
    "        self.tools = tools\n",
    "        self.agent = self._build_agent_from_config()\n",
    "\n",
    "    def _build_agent_from_config(self):\n",
    "        \"\"\"Build the agent graph with configured LLM\"\"\"\n",
    "        llm = ChatDatabricks(\n",
    "            endpoint=self.config.get(\"endpoint_name\"),\n",
    "            temperature=self.config.get(\"temperature\"),\n",
    "            max_tokens=self.config.get(\"max_tokens\"),\n",
    "        )\n",
    "        agent = create_tool_calling_agent(llm, tools=self.tools)\n",
    "        return agent\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        \"\"\"\n",
    "        Main prediction method - automatically traced by MLflow\n",
    "        \"\"\"\n",
    "        # Convert messages to dictionary format\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "        \n",
    "        # Invoke agent - this creates the trace automatically\n",
    "        output = self.agent.invoke(request)\n",
    "        \n",
    "        return ChatAgentResponse(**output)\n",
    "```\n",
    "\n",
    "### Setting Up the Agent\n",
    "\n",
    "```python\n",
    "# Initialize UC Function Client for tools\n",
    "uc_client = DatabricksFunctionClient()\n",
    "set_uc_function_client(uc_client)\n",
    "\n",
    "# Configuration\n",
    "catalog = \"agentic_ai\"\n",
    "schema = \"databricks\"\n",
    "LLM_ENDPOINT = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "\n",
    "baseline_config = {\n",
    "    \"endpoint_name\": LLM_ENDPOINT,\n",
    "    \"temperature\": 0.01,\n",
    "    \"max_tokens\": 1000\n",
    "}\n",
    "\n",
    "# Set up tools from Unity Catalog\n",
    "uc_tool_names = [f\"{catalog}.{schema}.search_web\"]\n",
    "uc_toolkit = UCFunctionToolkit(function_names=uc_tool_names)\n",
    "tools = [*uc_toolkit.tools]\n",
    "\n",
    "# Create the agent\n",
    "AGENT = DocsAgent(baseline_config, tools)\n",
    "```\n",
    "\n",
    "## Enabling MLflow Tracing\n",
    "\n",
    "MLflow provides automatic tracing for LangGraph agents. Here's how to enable it:\n",
    "\n",
    "```python\n",
    "import mlflow\n",
    "\n",
    "# Enable automatic tracing for LangChain/LangGraph\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "# Set up experiment for organizing traces\n",
    "mlflow.set_experiment(\"Agent_Tracing_Demo\")\n",
    "\n",
    "# Execute the agent - traces are captured automatically\n",
    "result = AGENT.predict([{\n",
    "    \"role\": \"user\", \n",
    "    \"content\": \"What is the latest news on OpenAI product releases? Provide results in bullet points\"\n",
    "}])\n",
    "```\n",
    "\n",
    "## Trace and Span Hierarchy: A Complete Walkthrough\n",
    "\n",
    "When the agent executes, MLflow creates a detailed trace with multiple spans. Let's walk through exactly what happens.\n",
    "\n",
    "### Example Query Execution\n",
    "\n",
    "```python\n",
    "user_query = \"What is the latest news on OpenAI product releases? Provide results in bullet points\"\n",
    "\n",
    "result = AGENT.predict([{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": user_query\n",
    "}])\n",
    "```\n",
    "\n",
    "### The Complete Trace Structure\n",
    "\n",
    "```\n",
    "üìä TRACE: agent_execution (trace_id: tr_abc123)\n",
    "‚îÇ   Duration: 8.45 seconds\n",
    "‚îÇ   Status: ‚úÖ OK\n",
    "‚îÇ   Total Tokens: 537\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ ü§ñ SPAN 1: DocsAgent.predict (span_id: sp_001)\n",
    "‚îÇ    ‚îÇ   Type: AGENT\n",
    "‚îÇ    ‚îÇ   Duration: 8.45s (100% of trace)\n",
    "‚îÇ    ‚îÇ   Input: {\"messages\": [{\"role\": \"user\", \"content\": \"What is the latest...\"}]}\n",
    "‚îÇ    ‚îÇ   Output: {\"messages\": [{\"role\": \"assistant\", \"content\": \"‚Ä¢ OpenAI launched...\"}]}\n",
    "‚îÇ    ‚îÇ\n",
    "‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ üîÑ SPAN 2: StateGraph.invoke (span_id: sp_002, parent: sp_001)\n",
    "‚îÇ         ‚îÇ   Type: CHAIN\n",
    "‚îÇ         ‚îÇ   Duration: 8.30s\n",
    "‚îÇ         ‚îÇ   Purpose: Execute the LangGraph workflow\n",
    "‚îÇ         ‚îÇ\n",
    "‚îÇ         ‚îú‚îÄ‚îÄ‚îÄ üß† SPAN 3: tool_calling_llm [1st call] (span_id: sp_003, parent: sp_002)\n",
    "‚îÇ         ‚îÇ    ‚îÇ   Type: LLM\n",
    "‚îÇ         ‚îÇ    ‚îÇ   Duration: 2.65s\n",
    "‚îÇ         ‚îÇ    ‚îÇ   Input: User query\n",
    "‚îÇ         ‚îÇ    ‚îÇ   Output: Tool call decision\n",
    "‚îÇ         ‚îÇ    ‚îÇ   Attributes:\n",
    "‚îÇ         ‚îÇ    ‚îÇ       - model: \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "‚îÇ         ‚îÇ    ‚îÇ       - temperature: 0.01\n",
    "‚îÇ         ‚îÇ    ‚îÇ       - input_tokens: 67\n",
    "‚îÇ         ‚îÇ    ‚îÇ       - output_tokens: 45\n",
    "‚îÇ         ‚îÇ    ‚îÇ       - total_tokens: 112\n",
    "‚îÇ         ‚îÇ    ‚îÇ       - has_tool_calls: true\n",
    "‚îÇ         ‚îÇ    ‚îÇ\n",
    "‚îÇ         ‚îú‚îÄ‚îÄ‚îÄ üõ†Ô∏è SPAN 4: search_web (span_id: sp_004, parent: sp_002)\n",
    "‚îÇ         ‚îÇ    ‚îÇ   Type: TOOL\n",
    "‚îÇ         ‚îÇ    ‚îÇ   Duration: 3.35s\n",
    "‚îÇ         ‚îÇ    ‚îÇ   Input: {\"query\": \"OpenAI latest product releases news 2024\"}\n",
    "‚îÇ         ‚îÇ    ‚îÇ   Output: \"Recent OpenAI developments include GPT-4 Turbo...\"\n",
    "‚îÇ         ‚îÇ    ‚îÇ   Attributes:\n",
    "‚îÇ         ‚îÇ    ‚îÇ       - tool_name: \"agentic_ai.databricks.search_web\"\n",
    "‚îÇ         ‚îÇ    ‚îÇ       - execution_time_ms: 3350\n",
    "‚îÇ         ‚îÇ    ‚îÇ\n",
    "‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ üß† SPAN 5: tool_calling_llm [2nd call] (span_id: sp_005, parent: sp_002)\n",
    "‚îÇ              ‚îÇ   Type: LLM\n",
    "‚îÇ              ‚îÇ   Duration: 2.10s\n",
    "‚îÇ              ‚îÇ   Input: Original query + Tool results\n",
    "‚îÇ              ‚îÇ   Output: Final formatted response\n",
    "‚îÇ              ‚îÇ   Attributes:\n",
    "‚îÇ              ‚îÇ       - model: \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "‚îÇ              ‚îÇ       - temperature: 0.01\n",
    "‚îÇ              ‚îÇ       - input_tokens: 245\n",
    "‚îÇ              ‚îÇ       - output_tokens: 180\n",
    "‚îÇ              ‚îÇ       - total_tokens: 425\n",
    "‚îÇ              ‚îÇ       - has_tool_calls: false\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ üìä TRACE SUMMARY\n",
    "     Total Duration: 8.45s\n",
    "     Total Tokens: 537 (input: 312, output: 225)\n",
    "     Estimated Cost: $0.0027\n",
    "     Status: Success ‚úÖ\n",
    "```\n",
    "\n",
    "## Deep Dive: Each Span Explained\n",
    "\n",
    "### Span 1: Agent Predict (Root Span)\n",
    "\n",
    "This is the entry point created by the `DocsAgent.predict()` method:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"span_id\": \"sp_001\",\n",
    "    \"name\": \"DocsAgent.predict\",\n",
    "    \"span_type\": \"AGENT\",\n",
    "    \"start_time\": 1732315680000,\n",
    "    \"end_time\": 1732315688450,\n",
    "    \"inputs\": {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the latest news on OpenAI product releases? Provide results in bullet points\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"outputs\": {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Based on the latest information:\\n\\n‚Ä¢ GPT-4 Turbo launched with enhanced capabilities...\",\n",
    "                \"additional_kwargs\": {}\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"attributes\": {\n",
    "        \"mlflow.agent.class\": \"DocsAgent\",\n",
    "        \"mlflow.agent.temperature\": 0.01,\n",
    "        \"mlflow.agent.max_tokens\": 1000,\n",
    "        \"mlflow.agent.endpoint\": \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Key Insights:**\n",
    "- Captures the complete user request and final response\n",
    "- Shows agent-level configuration\n",
    "- Measures end-to-end execution time\n",
    "\n",
    "### Span 2: StateGraph Invoke (Chain Execution)\n",
    "\n",
    "Created when `self.agent.invoke(request)` is called:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"span_id\": \"sp_002\",\n",
    "    \"parent_span_id\": \"sp_001\",\n",
    "    \"name\": \"StateGraph.invoke\",\n",
    "    \"span_type\": \"CHAIN\",\n",
    "    \"start_time\": 1732315680100,\n",
    "    \"end_time\": 1732315688400,\n",
    "    \"inputs\": {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the latest news on OpenAI product releases?\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"outputs\": {\n",
    "        \"messages\": [/* final response with tool results */]\n",
    "    },\n",
    "    \"attributes\": {\n",
    "        \"graph_type\": \"StateGraph\",\n",
    "        \"node_count\": 2,\n",
    "        \"edge_count\": 4\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Key Insights:**\n",
    "- Represents the entire LangGraph workflow\n",
    "- Parent of all node executions (LLM calls, tool calls)\n",
    "- Shows the graph structure\n",
    "\n",
    "### Span 3: First LLM Call (Tool Decision)\n",
    "\n",
    "Created by the `tool_calling_llm` node:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"span_id\": \"sp_003\",\n",
    "    \"parent_span_id\": \"sp_002\",\n",
    "    \"name\": \"tool_calling_llm\",\n",
    "    \"span_type\": \"LLM\",\n",
    "    \"start_time\": 1732315680150,\n",
    "    \"end_time\": 1732315682800,\n",
    "    \"inputs\": {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the latest news on OpenAI product releases?\"\n",
    "            }\n",
    "        ],\n",
    "        \"model\": \"databricks-meta-llama-3-3-70b-instruct\",\n",
    "        \"temperature\": 0.01,\n",
    "        \"max_tokens\": 1000\n",
    "    },\n",
    "    \"outputs\": {\n",
    "        \"content\": \"\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"name\": \"agentic_ai__databricks__search_web\",\n",
    "                \"args\": {\n",
    "                    \"query\": \"OpenAI latest product releases news 2024\"\n",
    "                },\n",
    "                \"id\": \"call_xyz789\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"attributes\": {\n",
    "        \"mlflow.chat.tokenUsage\": {\n",
    "            \"input_tokens\": 67,\n",
    "            \"output_tokens\": 45,\n",
    "            \"total_tokens\": 112\n",
    "        },\n",
    "        \"execution_time_ms\": 2650,\n",
    "        \"has_tool_calls\": true,\n",
    "        \"tool_call_count\": 1\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Key Insights:**\n",
    "- Shows LLM decided to call a tool\n",
    "- Captures token usage for cost tracking\n",
    "- Records exact tool call parameters\n",
    "- Shows execution latency\n",
    "\n",
    "### Span 4: Tool Execution (Search Web)\n",
    "\n",
    "Created by the `ChatAgentToolNode`:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"span_id\": \"sp_004\",\n",
    "    \"parent_span_id\": \"sp_002\",\n",
    "    \"name\": \"search_web\",\n",
    "    \"span_type\": \"TOOL\",\n",
    "    \"start_time\": 1732315682850,\n",
    "    \"end_time\": 1732315686200,\n",
    "    \"inputs\": {\n",
    "        \"tool_name\": \"agentic_ai__databricks__search_web\",\n",
    "        \"tool_input\": {\n",
    "            \"query\": \"OpenAI latest product releases news 2024\"\n",
    "        }\n",
    "    },\n",
    "    \"outputs\": {\n",
    "        \"content\": \"Recent OpenAI developments include:\\n- GPT-4 Turbo launch with 128K context window\\n- ChatGPT Enterprise features for businesses\\n- DALL-E 3 integration with ChatGPT\\n- Custom GPTs marketplace announcement...\"\n",
    "    },\n",
    "    \"attributes\": {\n",
    "        \"mlflow.tool.function_name\": \"agentic_ai.databricks.search_web\",\n",
    "        \"execution_time_ms\": 3350,\n",
    "        \"tool_status\": \"success\",\n",
    "        \"result_length\": 487\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Key Insights:**\n",
    "- Shows actual tool execution\n",
    "- Captures tool inputs and outputs\n",
    "- Tracks tool-specific latency\n",
    "- Can identify slow tools\n",
    "\n",
    "### Span 5: Second LLM Call (Response Generation)\n",
    "\n",
    "Another call to `tool_calling_llm` with tool results:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"span_id\": \"sp_005\",\n",
    "    \"parent_span_id\": \"sp_002\",\n",
    "    \"name\": \"tool_calling_llm\",\n",
    "    \"span_type\": \"LLM\",\n",
    "    \"start_time\": 1732315686250,\n",
    "    \"end_time\": 1732315688350,\n",
    "    \"inputs\": {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the latest news on OpenAI product releases?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\",\n",
    "                \"tool_calls\": [/* previous tool call */]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": \"Recent OpenAI developments include...\",\n",
    "                \"tool_call_id\": \"call_xyz789\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"outputs\": {\n",
    "        \"content\": \"Based on the latest information, here are the recent OpenAI product releases:\\n\\n‚Ä¢ GPT-4 Turbo with 128K context window for processing longer documents\\n‚Ä¢ ChatGPT Enterprise with advanced security and admin controls\\n‚Ä¢ DALL-E 3 integration for generating images within ChatGPT\\n‚Ä¢ Custom GPTs marketplace for specialized AI assistants\",\n",
    "        \"tool_calls\": []\n",
    "    },\n",
    "    \"attributes\": {\n",
    "        \"mlflow.chat.tokenUsage\": {\n",
    "            \"input_tokens\": 245,\n",
    "            \"output_tokens\": 180,\n",
    "            \"total_tokens\": 425\n",
    "        },\n",
    "        \"execution_time_ms\": 2100,\n",
    "        \"has_tool_calls\": false,\n",
    "        \"response_type\": \"text\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Key Insights:**\n",
    "- Shows LLM processing tool results\n",
    "- Higher input tokens (includes tool output)\n",
    "- No tool calls (final response)\n",
    "- Generates user-facing answer\n",
    "\n",
    "## Accessing and Analyzing Traces\n",
    "\n",
    "### Retrieving Traces Programmatically\n",
    "\n",
    "```python\n",
    "import mlflow\n",
    "\n",
    "# Execute the agent\n",
    "result = AGENT.predict([{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"What is the latest news on OpenAI?\"\n",
    "}])\n",
    "\n",
    "# Get the trace ID\n",
    "trace_id = mlflow.get_last_active_trace_id()\n",
    "print(f\"Trace ID: {trace_id}\")\n",
    "\n",
    "# Retrieve the complete trace\n",
    "trace = mlflow.get_trace(trace_id)\n",
    "\n",
    "# Access trace information\n",
    "print(f\"Duration: {trace.info.execution_duration}ms\")\n",
    "print(f\"Status: {trace.info.state}\")\n",
    "print(f\"Request: {trace.info.request_preview}\")\n",
    "print(f\"Response: {trace.info.response_preview}\")\n",
    "\n",
    "# Access token usage\n",
    "if trace.info.token_usage:\n",
    "    print(f\"Total Tokens: {trace.info.token_usage['total_tokens']}\")\n",
    "    print(f\"Input Tokens: {trace.info.token_usage['input_tokens']}\")\n",
    "    print(f\"Output Tokens: {trace.info.token_usage['output_tokens']}\")\n",
    "```\n",
    "\n",
    "### Analyzing Individual Spans\n",
    "\n",
    "```python\n",
    "# Iterate through all spans\n",
    "print(\"\\n=== Span Analysis ===\")\n",
    "for span in trace.data.spans:\n",
    "    print(f\"\\nSpan: {span.name}\")\n",
    "    print(f\"  Type: {span.span_type}\")\n",
    "    print(f\"  Duration: {span.end_time_unix_ms - span.start_time_unix_ms}ms\")\n",
    "    \n",
    "    # Check for token usage\n",
    "    if token_usage := span.get_attribute(\"mlflow.chat.tokenUsage\"):\n",
    "        print(f\"  Tokens: {token_usage['total_tokens']}\")\n",
    "    \n",
    "    # Check for tool information\n",
    "    if tool_name := span.get_attribute(\"mlflow.tool.function_name\"):\n",
    "        print(f\"  Tool: {tool_name}\")\n",
    "```\n",
    "\n",
    "### Searching Traces\n",
    "\n",
    "```python\n",
    "# Search traces by experiment\n",
    "traces = mlflow.search_traces(\n",
    "    experiment_names=[\"Agent_Tracing_Demo\"],\n",
    "    max_results=10\n",
    ")\n",
    "\n",
    "# Filter traces by tags\n",
    "traces = mlflow.search_traces(\n",
    "    filter_string=\"tags.use_case = 'analytics'\",\n",
    "    max_results=10\n",
    ")\n",
    "\n",
    "# Sort by execution time\n",
    "traces = mlflow.search_traces(\n",
    "    experiment_names=[\"Agent_Tracing_Demo\"],\n",
    "    order_by=[\"execution_duration DESC\"],\n",
    "    max_results=5\n",
    ")\n",
    "\n",
    "# Display results\n",
    "for trace in traces:\n",
    "    print(f\"Trace: {trace.info.trace_id}\")\n",
    "    print(f\"  Duration: {trace.info.execution_duration}ms\")\n",
    "    print(f\"  Request: {trace.info.request_preview[:50]}...\")\n",
    "    print(f\"  Status: {trace.info.state}\")\n",
    "    print()\n",
    "```\n",
    "\n",
    "## Key Differences: MLflow vs Non-MLflow Implementation\n",
    "\n",
    "Understanding what makes the MLflow version different is crucial:\n",
    "\n",
    "### Non-MLflow Version\n",
    "\n",
    "```python\n",
    "# Simple state without tracing support\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def tool_calling_llm(state: State) -> State:\n",
    "    \"\"\"No config, no tracing context\"\"\"\n",
    "    current_state = state[\"messages\"]\n",
    "    return {\"messages\": [llm_with_tools.invoke(current_state)]}\n",
    "\n",
    "# Regular ToolNode\n",
    "builder.add_node(\"tools\", ToolNode(tools=tools))\n",
    "```\n",
    "\n",
    "**What's Missing:**\n",
    "- ‚ùå No automatic tracing\n",
    "- ‚ùå No configuration flow\n",
    "- ‚ùå No token tracking\n",
    "- ‚ùå No span creation\n",
    "- ‚ùå Not deployment-ready\n",
    "\n",
    "### MLflow-Compatible Version\n",
    "\n",
    "```python\n",
    "# ChatAgentState with tracing support\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState\n",
    "\n",
    "def tool_calling_llm(state: ChatAgentState, config: RunnableConfig):\n",
    "    \"\"\"With config and tracing context\"\"\"\n",
    "    response = model_runnable.invoke(state, config)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# ChatAgentToolNode with automatic span creation\n",
    "builder.add_node(\"tools\", ChatAgentToolNode(tools=tools))\n",
    "```\n",
    "\n",
    "**What's Included:**\n",
    "- ‚úÖ Automatic trace creation\n",
    "- ‚úÖ Configuration propagation\n",
    "- ‚úÖ Token usage tracking\n",
    "- ‚úÖ Detailed span hierarchy\n",
    "- ‚úÖ Production-ready observability\n",
    "\n",
    "## Real-World Use Cases\n",
    "\n",
    "### Use Case 1: Debugging Slow Responses\n",
    "\n",
    "```python\n",
    "# Execute agent\n",
    "result = AGENT.predict([{\"role\": \"user\", \"content\": \"Explain quantum computing\"}])\n",
    "\n",
    "# Analyze the trace\n",
    "trace = mlflow.get_trace(mlflow.get_last_active_trace_id())\n",
    "\n",
    "# Find the slowest span\n",
    "slowest_span = max(\n",
    "    trace.data.spans,\n",
    "    key=lambda s: s.end_time_unix_ms - s.start_time_unix_ms\n",
    ")\n",
    "\n",
    "print(f\"Bottleneck: {slowest_span.name}\")\n",
    "print(f\"Duration: {slowest_span.end_time_unix_ms - slowest_span.start_time_unix_ms}ms\")\n",
    "\n",
    "# Identify if it's LLM or tool\n",
    "if slowest_span.span_type == \"TOOL\":\n",
    "    print(\"Tool execution is the bottleneck\")\n",
    "elif slowest_span.span_type == \"LLM\":\n",
    "    print(\"LLM call is the bottleneck\")\n",
    "```\n",
    "\n",
    "### Use Case 2: Cost Optimization\n",
    "\n",
    "```python\n",
    "# Track costs across multiple requests\n",
    "total_tokens = 0\n",
    "total_cost = 0.0\n",
    "\n",
    "# Cost per 1K tokens (example rates)\n",
    "INPUT_TOKEN_COST = 0.0001\n",
    "OUTPUT_TOKEN_COST = 0.0002\n",
    "\n",
    "for i in range(10):\n",
    "    result = AGENT.predict([{\"role\": \"user\", \"content\": f\"Query {i}\"}])\n",
    "    trace = mlflow.get_trace(mlflow.get_last_active_trace_id())\n",
    "    \n",
    "    if trace.info.token_usage:\n",
    "        input_tokens = trace.info.token_usage['input_tokens']\n",
    "        output_tokens = trace.info.token_usage['output_tokens']\n",
    "        \n",
    "        total_tokens += input_tokens + output_tokens\n",
    "        total_cost += (input_tokens / 1000 * INPUT_TOKEN_COST) + \\\n",
    "                      (output_tokens / 1000 * OUTPUT_TOKEN_COST)\n",
    "\n",
    "print(f\"Total Tokens: {total_tokens}\")\n",
    "print(f\"Total Cost: ${total_cost:.4f}\")\n",
    "print(f\"Average Cost per Request: ${total_cost/10:.4f}\")\n",
    "```\n",
    "\n",
    "### Use Case 3: Quality Monitoring\n",
    "\n",
    "```python\n",
    "# Monitor tool usage patterns\n",
    "traces = mlflow.search_traces(\n",
    "    experiment_names=[\"Agent_Tracing_Demo\"],\n",
    "    max_results=100\n",
    ")\n",
    "\n",
    "tool_usage = {}\n",
    "for trace in traces:\n",
    "    for span in trace.data.spans:\n",
    "        if span.span_type == \"TOOL\":\n",
    "            tool_name = span.name\n",
    "            tool_usage[tool_name] = tool_usage.get(tool_name, 0) + 1\n",
    "\n",
    "print(\"=== Tool Usage Statistics ===\")\n",
    "for tool, count in sorted(tool_usage.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{tool}: {count} calls\")\n",
    "```\n",
    "\n",
    "## Best Practices for Tracing\n",
    "\n",
    "### 1. Use Meaningful Experiment Names\n",
    "\n",
    "```python\n",
    "# Good: Descriptive experiment names\n",
    "mlflow.set_experiment(\"Production_Agent_Customer_Support\")\n",
    "mlflow.set_experiment(\"Dev_Agent_Testing_v2\")\n",
    "\n",
    "# Bad: Generic names\n",
    "mlflow.set_experiment(\"test\")\n",
    "mlflow.set_experiment(\"experiment1\")\n",
    "```\n",
    "\n",
    "### 2. Add Context with Tags\n",
    "\n",
    "```python\n",
    "# Add tags for filtering and analysis\n",
    "mlflow.set_tags({\n",
    "    \"environment\": \"production\",\n",
    "    \"user_tier\": \"enterprise\",\n",
    "    \"version\": \"2.1.0\",\n",
    "    \"use_case\": \"customer_analytics\"\n",
    "})\n",
    "```\n",
    "\n",
    "### 3. Monitor Critical Metrics\n",
    "\n",
    "```python\n",
    "def monitor_agent_performance(trace):\n",
    "    \"\"\"Monitor key performance indicators\"\"\"\n",
    "    duration = trace.info.execution_duration\n",
    "    tokens = trace.info.token_usage\n",
    "    \n",
    "    # Alert on slow responses\n",
    "    if duration > 10000:  # 10 seconds\n",
    "        print(f\"‚ö†Ô∏è ALERT: Slow response detected ({duration}ms)\")\n",
    "    \n",
    "    # Alert on high token usage\n",
    "    if tokens and tokens['total_tokens'] > 2000:\n",
    "        print(f\"‚ö†Ô∏è ALERT: High token usage ({tokens['total_tokens']} tokens)\")\n",
    "    \n",
    "    # Check for errors\n",
    "    if trace.info.state == \"ERROR\":\n",
    "        print(f\"‚ùå ERROR: Agent execution failed\")\n",
    "```\n",
    "\n",
    "### 4. Regularly Review Traces\n",
    "\n",
    "```python\n",
    "# Weekly performance review\n",
    "def weekly_trace_analysis():\n",
    "    traces = mlflow.search_traces(\n",
    "        experiment_names=[\"Production_Agent\"],\n",
    "        max_results=1000\n",
    "    )\n",
    "    \n",
    "    durations = [t.info.execution_duration for t in traces]\n",
    "    tokens = [t.info.token_usage['total_tokens'] \n",
    "              for t in traces if t.info.token_usage]\n",
    "    \n",
    "    print(f\"Average Duration: {sum(durations)/len(durations):.2f}ms\")\n",
    "    print(f\"95th Percentile Duration: {sorted(durations)[int(len(durations)*0.95)]:.2f}ms\")\n",
    "    print(f\"Average Tokens: {sum(tokens)/len(tokens):.2f}\")\n",
    "    print(f\"Total Cost: ${sum(tokens) * 0.0001:.2f}\")\n",
    "```\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "MLflow tracing transforms AI agent development and deployment by providing:\n",
    "\n",
    "1. **Complete Visibility**: See every step of agent execution\n",
    "2. **Performance Insights**: Identify bottlenecks and optimize\n",
    "3. **Cost Tracking**: Monitor token usage and costs\n",
    "4. **Debugging Power**: Pinpoint issues quickly\n",
    "5. **Production Readiness**: Monitor deployed agents in real-time\n",
    "\n",
    "By understanding traces (the complete journey) and spans (individual steps), you can build agents that are not just functional, but observable, debuggable, and production-ready.\n",
    "\n",
    "The key difference between a prototype and a production agent is observability. With MLflow tracing, you're not flying blind‚Äîyou have a detailed map of every agent execution, empowering you to build better, faster, and more reliable AI systems.\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Reference\n",
    "\n",
    "```python\n",
    "# Enable tracing\n",
    "import mlflow\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "# Create MLflow-compatible agent\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "\n",
    "def tool_calling_llm(state: ChatAgentState, config: RunnableConfig):\n",
    "    response = model_runnable.invoke(state, config)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Execute and retrieve trace\n",
    "result = agent.predict(messages)\n",
    "trace = mlflow.get_trace(mlflow.get_last_active_trace_id())\n",
    "\n",
    "# Analyze traces\n",
    "print(f\"Duration: {trace.info.execution_duration}ms\")\n",
    "print(f\"Tokens: {trace.info.token_usage}\")\n",
    "\n",
    "# Search traces\n",
    "traces = mlflow.search_traces(\n",
    "    experiment_names=[\"My_Agent\"],\n",
    "    filter_string=\"tags.use_case = 'analytics'\"\n",
    ")\n",
    "```\n",
    "\n",
    "Happy tracing! üöÄ"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3. Explain Traces and Span from Capstone Project",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
