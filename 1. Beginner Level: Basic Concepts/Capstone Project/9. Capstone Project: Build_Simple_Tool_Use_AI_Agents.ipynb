{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "515b618a-c313-401d-9402-93804602157a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "50fa7f8a-8764-4bb9-9968-48b681a0e4f1"
   },
   "source": [
    "# Build Simple Tool-Use AI Agents in LangGraph\n",
    "\n",
    "Here we will extend the capability of the previously built Augmented LLM with feedback from the tool execution back to the LLM node to process it and generate human-like answers to user queries.\n",
    "\n",
    "### Tool-based Agentic AI System\n",
    "\n",
    "- Dynamic Decision-Making: LLM determines whether to directly respond or invoke a tool based on the query context.\n",
    "- Seamless Tool Integration: External tools are integrated to handle specific tasks, such as real-time web queries or computations.\n",
    "- Workflow Flexibility: Conditional routing ensures efficient task delegation:\n",
    "  - Tool Required: Routes to tool execution.\n",
    "  - No Tool Required: Ends the workflow with an LLM response.\n",
    "- Feedback Loop: Incorporates a feedback loop to improve responses by combining LLM insights and tool outputs to further improve responses or call more tools if needed\n",
    "\n",
    "![](https://i.imgur.com/DHxiOLl.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04fe71a5-256e-4bcc-b31d-c5e3a5ebe04a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ff151ef1-fa30-482a-94da-8f49964afbc3"
   },
   "outputs": [],
   "source": [
    "!pip install -qqqq langchain==0.3.14\n",
    "!pip install -qqqq langchain-openai==0.3.0\n",
    "!pip install -qqqq langchain-community==0.3.14\n",
    "!pip install -qqqq langgraph==0.2.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "847bdcd8-2c51-4b18-a049-b6323b067fa5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq mlflow databricks-langchain pydantic databricks-agents unitycatalog-langchain[databricks]\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5837f76a-28f7-42f8-ae91-e8465e184117",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "H9c37cLnSrbg"
   },
   "source": [
    "## Enter Open AI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "672e0cf8-fe44-4f03-bb09-3fa3fcec3d4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cv3JzCEx_PAd",
    "outputId": "e9fc3c4f-ce4e-47cd-ba27-6b890da5af92"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "# OPENAI_KEY = getpass('Enter Open AI API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3587013-49ee-4ba0-a4e6-9cb5dccaf6d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ucWRRI3QztL2"
   },
   "source": [
    "## Enter Tavily Search API Key\n",
    "\n",
    "Get a free API key from [here](https://tavily.com/#api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4143b4c2-3153-4230-90c8-26ee9bb3a57b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mK-1WLzOrJdb",
    "outputId": "e62f3ede-fde8-4793-9c5c-4175b636504c"
   },
   "outputs": [],
   "source": [
    "TAVILY_API_KEY = \"\" #getpass('Enter Tavily Search API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28c3b2b8-140b-4efe-9759-2e1a37e1ed35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1T0s0um5Svfa"
   },
   "source": [
    "## Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64d6009d-1f4f-4e73-94df-cd835c88b264",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "x1YSuHNF_lbh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "749c3310-4ec3-4e59-b28c-9445421adf87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "5999f8d0-989f-4638-8ade-5c257cbadfe8"
   },
   "source": [
    "## State\n",
    "\n",
    "First, define the [State](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) of the graph.\n",
    "\n",
    "The State schema serves as the input schema for all Nodes and Edges in the graph.\n",
    "\n",
    "Let's use the `TypedDict` class from python's `typing` module as our schema, which provides type hints for the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46011ea8-82f6-4cac-b43c-e6aa4d23bca4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "6a90709b-ddfa-4671-8acc-c59969a29991"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51ae22a0-fd55-466b-9ebe-277ca8c18802",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "mMwPwbV-mNQm"
   },
   "source": [
    "## Augment the LLM with tools\n",
    "\n",
    "Here we define our custom search tool and then bind it to the LLM to augment the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2703b088-fc47-4924-976a-1077effd6082",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks_langchain.uc_ai import (\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "\n",
    "uc_client = DatabricksFunctionClient()\n",
    "set_uc_function_client(uc_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "615188cc-1035-489c-af92-3bda68744aa1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "2lYXBn1ImzlB"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from databricks_langchain import ChatDatabricks\n",
    "\n",
    "# TODO: Replace with your model serving endpoint\n",
    "LLM_ENDPOINT = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT)\n",
    "\n",
    "\n",
    "\n",
    "def search_web(query: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Search the web for a query. Userful for general information or general news\n",
    "    Args:\n",
    "        query (string): Input text.\n",
    "    Returns:\n",
    "        dict: Output in dictionary format.\n",
    "\n",
    "    \"\"\"\n",
    "    from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "    import os\n",
    "\n",
    "    TAVILY_API_KEY = \"\"\n",
    "    os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY\n",
    "\n",
    "    \n",
    "    tavily_search = TavilySearchAPIWrapper()\n",
    "\n",
    "    results = tavily_search.raw_results(query=query,\n",
    "                                        max_results=10,\n",
    "                                        search_depth='advanced',\n",
    "                                        include_raw_content=True)\n",
    "    return results\n",
    "\n",
    "# TODO fill in your catalog and schema name\n",
    "catalog = \"agentic_ai\"\n",
    "schema = \"databricks\"\n",
    "\n",
    "assert (catalog and schema)\n",
    "\n",
    "# Create the function within the Unity Catalog catalog and schema specified\n",
    "function_info = uc_client.create_python_function(\n",
    "    func=search_web,\n",
    "    catalog=catalog,\n",
    "    schema=schema,\n",
    "    replace=True,  # Set to True to overwrite if the function already exists\n",
    "    dependencies=[\n",
    "        \"langchain-community==0.3.14\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "uc_tool_names = [f\"{catalog}.{schema}.search_web\"]\n",
    "uc_toolkit = UCFunctionToolkit(function_names=uc_tool_names)\n",
    "tools=[*uc_toolkit.tools]\n",
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5e262cc-b3e9-4d09-82e0-dad782b47bcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wjOYMS0rn1CF",
    "outputId": "672b4674-d154-4331-aad0-100075ccd7a9"
   },
   "outputs": [],
   "source": [
    "llm_with_tools.invoke('what is the latest news on nvidia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c9de8b9-6952-4494-8319-d66c5c269d0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "NPFD28OWjGQM"
   },
   "source": [
    "## Create the Graph with the Tool-Use Agentic System\n",
    "\n",
    "![](https://i.imgur.com/DHxiOLl.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fe80e52-a269-4bdf-ac31-ad0b574c3093",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "IJvHs_Py3uCV"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import Annotated, Literal\n",
    "\n",
    "# from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# Custom tools_condition function\n",
    "def tools_condition(state: State) -> Literal[\"tools\", END]:\n",
    "    \"\"\"Route to tools if the last message has tool calls, otherwise end.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # Check if the last message has tool calls\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "# Custom Tool Node function\n",
    "def tool_node(state: State) -> State:\n",
    "    \"\"\"Execute tools based on tool calls in the last message\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    tool_calls = last_message.tool_calls if hasattr(last_message, 'tool_calls') else []\n",
    "    \n",
    "    tool_messages = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "        \n",
    "        # Find and execute the tool\n",
    "        tool = next((t for t in tools if t.name == tool_name), None)\n",
    "        if tool:\n",
    "            result = tool.invoke(tool_args)\n",
    "            tool_messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": str(result),\n",
    "                \"tool_call_id\": tool_call[\"id\"]\n",
    "            })\n",
    "    \n",
    "    return {\"messages\": tool_messages}\n",
    "\n",
    "# Augmented LLM with Tools Node function\n",
    "def tool_calling_llm(state: State) -> State:\n",
    "    current_state = state[\"messages\"]\n",
    "    return {\"messages\": [llm_with_tools.invoke(current_state)]}\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", tool_node)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "\n",
    "# Conditional Edge\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from LLM is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from LLM is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    "    [\"tools\", END]\n",
    ")\n",
    "builder.add_edge(\"tools\", \"tool_calling_llm\") # this is the key feedback loop\n",
    "builder.add_edge(\"tools\", END)\n",
    "agent = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8601fa38-1e07-42a5-9d78-e20ac59bf77f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "JR2L3D5Y3uH9",
    "outputId": "1b606d4e-4216-4cdb-ba2a-4581df847527"
   },
   "outputs": [],
   "source": [
    "\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50e2a182-a515-4bd3-a6b6-2c0a52106cdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db16ab8d-b817-4f3a-befc-a02b579c4fca",
    "outputId": "91524848-d16b-439b-953d-5396a196d083"
   },
   "outputs": [],
   "source": [
    "user_input = \"Explain AI in 2 bullets\"\n",
    "for event in agent.stream({\"messages\": user_input},\n",
    "                          stream_mode='values'):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5888adba-4604-432b-bbd9-26819d14b57e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-zYQrB6383i",
    "outputId": "29828380-44a6-48ea-824a-87fde936bf18"
   },
   "outputs": [],
   "source": [
    "user_input = \"What is the latest news on OpenAI product releases\"\n",
    "for event in agent.stream({\"messages\": user_input},\n",
    "                          stream_mode='values'):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e344451-b9ff-4019-a44e-55ff96013b7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICTlpMAqnL8L",
    "outputId": "07dbb9e8-5f69-4f5e-dc51-ee5e19c91ac3"
   },
   "outputs": [],
   "source": [
    "event['messages'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08173da9-d548-4226-b7a5-2ffda52ee77f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "T4h42-u94Jmb",
    "outputId": "6e2b715e-849d-47fd-c639-eafcdcae93b4"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(event['messages'][-1].content))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7536940233490353,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "9. Capstone Project: Build_Simple_Tool_Use_AI_Agents",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
