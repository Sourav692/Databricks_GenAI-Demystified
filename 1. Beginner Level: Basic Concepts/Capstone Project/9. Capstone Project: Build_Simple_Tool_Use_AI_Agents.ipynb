{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "515b618a-c313-401d-9402-93804602157a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "50fa7f8a-8764-4bb9-9968-48b681a0e4f1"
   },
   "source": [
    "# Build Simple Tool-Use AI Agents in LangGraph\n",
    "\n",
    "Here we will extend the capability of the previously built Augmented LLM with feedback from the tool execution back to the LLM node to process it and generate human-like answers to user queries.\n",
    "\n",
    "### Tool-based Agentic AI System\n",
    "\n",
    "- Dynamic Decision-Making: LLM determines whether to directly respond or invoke a tool based on the query context.\n",
    "- Seamless Tool Integration: External tools are integrated to handle specific tasks, such as real-time web queries or computations.\n",
    "- Workflow Flexibility: Conditional routing ensures efficient task delegation:\n",
    "  - Tool Required: Routes to tool execution.\n",
    "  - No Tool Required: Ends the workflow with an LLM response.\n",
    "- Feedback Loop: Incorporates a feedback loop to improve responses by combining LLM insights and tool outputs to further improve responses or call more tools if needed\n",
    "\n",
    "![](https://i.imgur.com/DHxiOLl.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04fe71a5-256e-4bcc-b31d-c5e3a5ebe04a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ff151ef1-fa30-482a-94da-8f49964afbc3"
   },
   "outputs": [],
   "source": [
    "!pip install -qqqq langchain==0.3.14\n",
    "!pip install -qqqq langchain-openai==0.3.0\n",
    "!pip install -qqqq langchain-community==0.3.14\n",
    "!pip install -qqqq langgraph==0.2.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "847bdcd8-2c51-4b18-a049-b6323b067fa5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq mlflow databricks-langchain pydantic databricks-agents unitycatalog-langchain[databricks]\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "672e0cf8-fe44-4f03-bb09-3fa3fcec3d4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cv3JzCEx_PAd",
    "outputId": "e9fc3c4f-ce4e-47cd-ba27-6b890da5af92"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from databricks_langchain.uc_ai import (\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from databricks_langchain import ChatDatabricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "749c3310-4ec3-4e59-b28c-9445421adf87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "5999f8d0-989f-4638-8ade-5c257cbadfe8"
   },
   "source": [
    "## State\n",
    "\n",
    "First, define the [State](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) of the graph.\n",
    "\n",
    "The State schema serves as the input schema for all Nodes and Edges in the graph.\n",
    "\n",
    "Let's use the `TypedDict` class from python's `typing` module as our schema, which provides type hints for the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46011ea8-82f6-4cac-b43c-e6aa4d23bca4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "6a90709b-ddfa-4671-8acc-c59969a29991"
   },
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51ae22a0-fd55-466b-9ebe-277ca8c18802",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "mMwPwbV-mNQm"
   },
   "source": [
    "## Augment the LLM with tools\n",
    "\n",
    "Here we define our custom search tool and then bind it to the LLM to augment the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2703b088-fc47-4924-976a-1077effd6082",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "uc_client = DatabricksFunctionClient()\n",
    "set_uc_function_client(uc_client)\n",
    "\n",
    "LLM_ENDPOINT = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT)\n",
    "\n",
    "catalog = \"agentic_ai\"\n",
    "schema = \"databricks\"\n",
    "\n",
    "uc_tool_names = [f\"{catalog}.{schema}.search_web\"]\n",
    "uc_toolkit = UCFunctionToolkit(function_names=uc_tool_names)\n",
    "tools=[*uc_toolkit.tools]\n",
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5e262cc-b3e9-4d09-82e0-dad782b47bcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wjOYMS0rn1CF",
    "outputId": "672b4674-d154-4331-aad0-100075ccd7a9"
   },
   "outputs": [],
   "source": [
    "llm_with_tools.invoke('what is the latest news on nvidia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c9de8b9-6952-4494-8319-d66c5c269d0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "NPFD28OWjGQM"
   },
   "source": [
    "## Create the Graph with the Tool-Use Agentic System\n",
    "\n",
    "![](https://i.imgur.com/DHxiOLl.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fe80e52-a269-4bdf-ac31-ad0b574c3093",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "IJvHs_Py3uCV"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import Annotated, Literal\n",
    "\n",
    "# from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# Custom tools_condition function\n",
    "def tools_condition(state: State) -> Literal[\"tools\", END]:\n",
    "    \"\"\"Route to tools if the last message has tool calls, otherwise end.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # Check if the last message has tool calls\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "# Custom Tool Node function\n",
    "def tool_node(state: State) -> State:\n",
    "    \"\"\"Execute tools based on tool calls in the last message\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    tool_calls = last_message.tool_calls if hasattr(last_message, 'tool_calls') else []\n",
    "    \n",
    "    tool_messages = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "        \n",
    "        # Find and execute the tool\n",
    "        tool = next((t for t in tools if t.name == tool_name), None)\n",
    "        if tool:\n",
    "            result = tool.invoke(tool_args)\n",
    "            tool_messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": str(result),\n",
    "                \"tool_call_id\": tool_call[\"id\"]\n",
    "            })\n",
    "    \n",
    "    return {\"messages\": tool_messages}\n",
    "\n",
    "# Augmented LLM with Tools Node function\n",
    "def tool_calling_llm(state: State) -> State:\n",
    "    current_state = state[\"messages\"]\n",
    "    return {\"messages\": [llm_with_tools.invoke(current_state)]}\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", tool_node)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "\n",
    "# Conditional Edge\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from LLM is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from LLM is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    "    [\"tools\", END]\n",
    ")\n",
    "builder.add_edge(\"tools\", \"tool_calling_llm\") # this is the key feedback loop\n",
    "builder.add_edge(\"tools\", END)\n",
    "agent = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f7a93b7-8370-4c55-9415-cc5a11bc12e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50e2a182-a515-4bd3-a6b6-2c0a52106cdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db16ab8d-b817-4f3a-befc-a02b579c4fca",
    "outputId": "91524848-d16b-439b-953d-5396a196d083"
   },
   "outputs": [],
   "source": [
    "user_input = \"Explain AI in 2 bullets\"\n",
    "for event in agent.stream({\"messages\": user_input},\n",
    "                          stream_mode='values'):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5888adba-4604-432b-bbd9-26819d14b57e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-zYQrB6383i",
    "outputId": "29828380-44a6-48ea-824a-87fde936bf18"
   },
   "outputs": [],
   "source": [
    "user_input = \"What is the latest news on OpenAI product releases\"\n",
    "for event in agent.stream({\"messages\": user_input},\n",
    "                          stream_mode='values'):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e344451-b9ff-4019-a44e-55ff96013b7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICTlpMAqnL8L",
    "outputId": "07dbb9e8-5f69-4f5e-dc51-ee5e19c91ac3"
   },
   "outputs": [],
   "source": [
    "event['messages'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08173da9-d548-4226-b7a5-2ffda52ee77f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "T4h42-u94Jmb",
    "outputId": "6e2b715e-849d-47fd-c639-eafcdcae93b4"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(event['messages'][-1].content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebf95c09-fcb0-4779-9b21-4345d4bac973",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": "A10",
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8870256162052502,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "9. Capstone Project: Build_Simple_Tool_Use_AI_Agents",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
