{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "575b08b5-aa8a-4acd-a4a1-9cd8c6f823fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Example: Structured data extraction, batch inference & evaluation\n",
    "This notebook demonstrates how to perform basic structured data extraction using `ai_query` ([AWS](https://docs.databricks.com/aws/sql/language-manual/functions/ai_query) | [Azure](https://learn.microsoft.com/azure/databricks/sql/language-manual/functions/ai_query)). \n",
    "\n",
    "The process illustrates how to effectively transform raw, unstructured data into organized, actionable information through automated extraction techniques.\n",
    "\n",
    "This notebook also shows how to leverage Mosaic AI Agent Evaluation ([AWS](https://docs.databricks.com/aws/generative-ai/agent-evaluation/) | [Azure](https://learn.microsoft.com/azure/databricks/generative-ai/agent-evaluation/)) to evaluate the accuracy if ground truth data is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cb592d2-1ba2-4453-bc8a-9fb5686a0b56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade \"mlflow[databricks]>=3.1.0\" \n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eba2d1f1-d47b-4906-a7ca-7906003e14e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Perform batch inference using `ai_query`\n",
    "To demonstrate how to use `ai_query` for structured data extraction, this notebook creates a simulated dataset of employment contracts. This dummy dataset will serve as a testbed for entity extraction, focusing on key information such as employer and employee names. It includes the ground-truth of data to be extracted, which is used later for evaluation.\n",
    "\n",
    "This notebook then utilizes this dataset to conduct batch inference using `ai_query`([AWS](https://docs.databricks.com/aws/sql/language-manual/functions/ai_query) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/functions/ai_query))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e86576bd-4025-42eb-ad0b-155745401f6b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Dummy contract data"
    }
   },
   "outputs": [],
   "source": [
    "# Some dummy employment contracts including ground truth\n",
    "\n",
    "employment_contracts = [\n",
    "    dict(\n",
    "        contract_text=\"This Employment Agreement is made on May 15, 2023, between TechCorp Inc. (the 'Employer') and Sarah Johnson (the 'Employee'). The Employee will commence work as a Software Engineer on June 1, 2023, with an annual salary of $85,000. The Employee agrees to a probationary period of 3 months.\",\n",
    "        ground_truth='{\"signature_date\": \"May 15, 2023\", \"employer\": \"TechCorp Inc.\", \"employee\": \"Sarah Johnson\", \"bonuses\": [\"N/A\"]}'\n",
    "    ),\n",
    "    dict(\n",
    "        contract_text=\"Employment Contract: Effective July 1, 2023, DataSystems LLC (hereinafter 'Employer') agrees to employ Michael Chen (hereinafter 'Employee') as a Data Analyst. The Employee's starting salary shall be $70,000 per annum. This agreement includes a non-compete clause effective for 12 months post-termination.\",\n",
    "        ground_truth='{\"signature_date\": \"July 1, 2023\", \"employer\": \"DataSystems LLC\", \"employee\": \"Michael Chen\", \"bonuses\": [\"N/A\"]}'\n",
    "    ),\n",
    "    dict(\n",
    "        contract_text=\"On August 15, 2023, CloudNet Solutions ('Employer') and Emma Rodriguez ('Employee') enter into this employment agreement. The Employee is hired as a Network Administrator with a starting date of September 1, 2023. The annual compensation is set at $78,000, with a signing bonus of $5,000.\",\n",
    "        ground_truth='{\"signature_date\": \"August 15, 2023\", \"employer\":\"CloudNet Solutions\", \"employee\": \"Emma Rodriguez\", \"bonuses\":[\"$5,000 signing bonus\"]}'\n",
    "    ),\n",
    "    dict(\n",
    "        contract_text=\"This contract, dated October 1, 2023, is between AI Innovations Corp ('Employer') and Dr. James Lee ('Employee'). Dr. Lee is appointed as Chief Research Scientist, commencing on November 1, 2023. The base salary is $150,000 per year, with performance-based bonuses as outlined in Appendix A.\",\n",
    "        ground_truth='{\"signature_date\": \"October 1, 2023\", \"employer\": \"AI Innovations Corp\", \"employee\": \"Dr. James Lee\", \"bonuses\":[\"performance-based bonuses as outlined in Appendix A\"]}'\n",
    "    ),\n",
    "]\n",
    "\n",
    "employment_contracts_df = spark.createDataFrame(employment_contracts)\n",
    "employment_contracts_df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5c6d39d-68f2-4ccb-be50-d59f5f0d99fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Structured data extraction with `ai_query`\n",
    "The next cell defines the main input required to perform structured data extraction with `ai_query`:\n",
    "- The LLM endpoint name\n",
    "- The prompt instructing the LLM to perform data extraction and to use JSON as response format\n",
    "- The JSON schema of the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f22cede9-ef45-4b66-a8a9-4cf9699b5745",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define prompt and response format"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "\n",
    "PROMPT = \"\"\"You are an AI assistant specialized in analyzing legal documents. \n",
    "Your task is to extract relevant information from a given contract document. \n",
    "Your output must be a structured JSON object.\n",
    "\n",
    "Instructions:\n",
    "1. Carefully read the entire contract document provided at the end of this prompt.\n",
    "2. Extract the relevant information.\n",
    "3. Present your findings in JSON format as specified below.\n",
    "\n",
    "Important Notes:\n",
    "- Extract only relevant information. \n",
    "- Consider the context of the entire contract when determining relevance.\n",
    "- Do not be verbose, only respond with the correct format and information.\n",
    "- Some questions may have no relevant excerpts. Just return \"N/A\" or [\"N/A\"] depending on the expected type in this case.\n",
    "- Do not include additional JSON keys beyond the ones listed here.\n",
    "- Do not include the same key multiple times in the JSON.\n",
    "\n",
    "Expected JSON keys and explanation of what they are:\n",
    "- signature_date: The signature date of the contract.\n",
    "- employer: The employers name.\n",
    "- employee: The employees name.\n",
    "- bonuses: A list of any mentioned specific bonus.\n",
    "\n",
    "Contract to analyze: \n",
    "\"\"\"\n",
    "\n",
    "response_format = json.dumps({\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"employment_contract_extraction\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"signature_date\": {\"type\": \"string\"},\n",
    "                \"employer\": {\"type\": \"string\"},\n",
    "                \"employee\": {\"type\": \"string\"},\n",
    "                \"bonuses\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "            },\n",
    "            \"strict\": True,\n",
    "        },\n",
    "    },\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0185df1c-26ae-431a-9826-f172b0879f8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Batch inference\n",
    "Below, `ai_query` is applied to the Spark dataframe as a SQL expression using the inputs defined above. The LLM's response, which is a JSON string, is parsed to extract the individual data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "291acda3-7f47-4763-8a56-a484e0f28dfc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Use ai_query for batch inference"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, from_json\n",
    "\n",
    "# define query\n",
    "ai_query_expr = f\"\"\"\n",
    "  ai_query(\n",
    "    endpoint => '{LLM_ENDPOINT_NAME}',\n",
    "    request => CONCAT('{PROMPT}', contract_text),\n",
    "    responseFormat => '{response_format}',\n",
    "    modelParameters => named_struct('temperature', 0.)\n",
    "    ) AS response\n",
    "  \"\"\"\n",
    "\n",
    "# the json schema of the LLM response string which we want to unpack\n",
    "json_schema = \"STRUCT<signature_date STRING, employee STRING, employer STRING, bonuses ARRAY<STRING>>\"\n",
    "\n",
    "# run the batch query and unpack the response\n",
    "employment_contracts_df = employment_contracts_df.selectExpr(\n",
    "    \"*\", ai_query_expr\n",
    ").withColumn(\"parsed_response\", from_json(col(\"response\"), json_schema))\n",
    "\n",
    "employment_contracts_df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a11d8c0-47a0-4e4e-8783-529e5f471257",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluate the agent with Agent Evaluation\n",
    "\n",
    "To assess the agent's quality, we'll use the Agent Evaluation framework ([AWS](https://docs.databricks.com/en/generative-ai/agent-evaluation/index.html) | [Azure](https://learn.microsoft.com/azure/databricks/generative-ai/agent-evaluation/)). This approach employs a correctness judge to compare expected entities (or facts) with the actual response, providing a comprehensive evaluation of the agent's performance.\n",
    "\n",
    "_Note: An alternative approach would be to compute metrics such as `recall` and `precision` for individual entities, though this would require additional data transformations or [custom metrics](https://mlflow.org/docs/latest/python_api/mlflow.metrics.html#mlflow-metrics)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29f8015c-effe-472d-815e-56c7189af7b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.genai import evaluate\n",
    "from mlflow.genai.scorers import Correctness\n",
    "\n",
    "# prepare the evaluation dataframe expected by mlflow.genai.evaluate()\n",
    "eval_pdf = employment_contracts_df.select(\n",
    "    col(\"contract_text\"),\n",
    "    col(\"response\").alias(\"outputs\"),\n",
    "    col(\"ground_truth\")\n",
    ").toPandas()\n",
    "\n",
    "# Convert 'inputs' to required dict format\n",
    "eval_pdf[\"inputs\"] = eval_pdf[\"contract_text\"].apply(\n",
    "    lambda x: {\"contract_text\": x}\n",
    ")\n",
    "eval_pdf[\"expectations\"] = eval_pdf[\"ground_truth\"].apply(\n",
    "    lambda x: {\"expected_facts\": x.split(\",\")}\n",
    ")\n",
    "eval_pdf = eval_pdf.drop(columns=[\"contract_text\", \"ground_truth\"])\n",
    "\n",
    "# run evaluation and track results in mlflow experiment\n",
    "with mlflow.start_run():\n",
    "    results = mlflow.genai.evaluate(\n",
    "        data=eval_pdf,\n",
    "        scorers=[Correctness()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc3e0374-a78b-470b-925b-92be3ab9a329",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next steps\n",
    "For further insights and related examples of structured data extraction on Databricks, consider exploring these comprehensive technical blog posts:\n",
    "- [End-to-End Structured Extraction with LLM – Part 1: Batch Entity Extraction](https://community.databricks.com/t5/technical-blog/end-to-end-structured-extraction-with-llm-part-1-batch-entity/ba-p/98396)\n",
    "- [End-to-End Structured Extraction with LLM – Part 2: Fine-Tuning with Synthetic Data](https://community.databricks.com/t5/technical-blog/end-to-end-structured-extraction-with-llm-part-2-fine-tuning/ba-p/99900)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1335034106274547,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "7. ai_query",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
