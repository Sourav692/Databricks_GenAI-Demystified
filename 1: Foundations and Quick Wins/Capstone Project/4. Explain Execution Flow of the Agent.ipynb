{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "334a071f-50c4-4610-a087-44e5a1b335ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Execution Flow of MLflow Compatible Agent: A Step-by-Step Deep Dive\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Understanding how an MLflow-compatible agent executes internally is crucial for debugging, optimization, and building production-ready AI systems. In this article, we'll trace through every single step of execution, from the moment a user makes a request to when they receive a response.\n",
    "\n",
    "We'll use a real example with actual code from the GitHub repository and follow the execution flow line by line, showing exactly what happens at each stage.\n",
    "\n",
    "## Sample Request Setup\n",
    "\n",
    "Let's start with our example request:\n",
    "\n",
    "```python\n",
    "# User asks a question that requires tool usage\n",
    "user_query = \"What is the latest news on OpenAI product releases? Provide results in bullet points\"\n",
    "```\n",
    "\n",
    "This query will trigger:\n",
    "1. An LLM call to understand the query\n",
    "2. A tool call to search the web\n",
    "3. Another LLM call to format the results\n",
    "\n",
    "Let's trace through the complete execution!\n",
    "\n",
    "## Complete Agent Code\n",
    "\n",
    "First, let's review the complete MLflow-compatible agent code:\n",
    "\n",
    "```python\n",
    "import mlflow\n",
    "from typing import Annotated, Optional, Any\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from databricks_langchain.uc_ai import (\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langgraph.prebuilt.tool_node import tools_condition\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import ChatAgentMessage, ChatAgentResponse, ChatContext\n",
    "from mlflow.models import ModelConfig\n",
    "\n",
    "# Step 1: Create the agent graph\n",
    "def create_tool_calling_agent(model, tools):\n",
    "    \"\"\"\n",
    "    Creates a LangGraph-based tool-calling agent with MLflow tracing\n",
    "    \"\"\"\n",
    "    llm_with_tools = model.bind_tools(tools=tools)\n",
    "    \n",
    "    # Preprocessor to extract messages from state\n",
    "    preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n",
    "    model_runnable = preprocessor | llm_with_tools\n",
    "\n",
    "    def tool_calling_llm(state: ChatAgentState, config: RunnableConfig):\n",
    "        \"\"\"Node function that calls the LLM\"\"\"\n",
    "        response = model_runnable.invoke(state, config)\n",
    "        return {\"messages\": [response]}\n",
    "    \n",
    "    # Build the graph\n",
    "    builder = StateGraph(ChatAgentState)\n",
    "    builder.add_node(\"tool_calling_llm\", RunnableLambda(tool_calling_llm))\n",
    "    builder.add_node(\"tools\", ChatAgentToolNode(tools=tools))\n",
    "    builder.add_edge(START, \"tool_calling_llm\")\n",
    "    \n",
    "    builder.add_conditional_edges(\n",
    "        \"tool_calling_llm\",\n",
    "        tools_condition,\n",
    "        [\"tools\", END]\n",
    "    )\n",
    "    builder.add_edge(\"tools\", \"tool_calling_llm\")\n",
    "    \n",
    "    return builder.compile()\n",
    "\n",
    "# Step 2: Create the MLflow-compatible agent class\n",
    "class DocsAgent(ChatAgent):\n",
    "    def __init__(self, config, tools):\n",
    "        self.config = ModelConfig(development_config=config)\n",
    "        self.tools = tools\n",
    "        self.agent = self._build_agent_from_config()\n",
    "\n",
    "    def _build_agent_from_config(self):\n",
    "        llm = ChatDatabricks(\n",
    "            endpoint=self.config.get(\"endpoint_name\"),\n",
    "            temperature=self.config.get(\"temperature\"),\n",
    "            max_tokens=self.config.get(\"max_tokens\"),\n",
    "        )\n",
    "        agent = create_tool_calling_agent(llm, tools=self.tools)\n",
    "        return agent\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "        output = self.agent.invoke(request)\n",
    "        return ChatAgentResponse(**output)\n",
    "\n",
    "# Step 3: Initialize the agent\n",
    "uc_client = DatabricksFunctionClient()\n",
    "set_uc_function_client(uc_client)\n",
    "\n",
    "catalog = \"agentic_ai\"\n",
    "schema = \"databricks\"\n",
    "LLM_ENDPOINT = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "\n",
    "baseline_config = {\n",
    "    \"endpoint_name\": LLM_ENDPOINT,\n",
    "    \"temperature\": 0.01,\n",
    "    \"max_tokens\": 1000\n",
    "}\n",
    "\n",
    "uc_tool_names = [f\"{catalog}.{schema}.search_web\"]\n",
    "uc_toolkit = UCFunctionToolkit(function_names=uc_tool_names)\n",
    "tools = [*uc_toolkit.tools]\n",
    "\n",
    "AGENT = DocsAgent(baseline_config, tools)\n",
    "```\n",
    "\n",
    "## Execution Flow: Step-by-Step Breakdown\n",
    "\n",
    "Now let's execute our sample request and trace through every step:\n",
    "\n",
    "```python\n",
    "# Enable MLflow tracing\n",
    "mlflow.langchain.autolog()\n",
    "mlflow.set_experiment(\"Agent_Execution_Flow_Demo\")\n",
    "\n",
    "# Execute the request\n",
    "result = AGENT.predict([{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"What is the latest news on OpenAI product releases? Provide results in bullet points\"\n",
    "}])\n",
    "```\n",
    "\n",
    "### Phase 1: Request Initiation (AGENT.predict)\n",
    "\n",
    "**Code Entry Point:**\n",
    "```python\n",
    "def predict(\n",
    "    self,\n",
    "    messages: list[ChatAgentMessage],\n",
    "    context: Optional[ChatContext] = None,\n",
    "    custom_inputs: Optional[dict[str, Any]] = None,\n",
    ") -> ChatAgentResponse:\n",
    "```\n",
    "\n",
    "**What Happens:**\n",
    "\n",
    "**Step 1.1: Method Invocation**\n",
    "```python\n",
    "# User calls:\n",
    "result = AGENT.predict([{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"What is the latest news on OpenAI product releases? Provide results in bullet points\"\n",
    "}])\n",
    "\n",
    "# Internally, the messages parameter receives:\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is the latest news on OpenAI product releases? Provide results in bullet points\"\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "**MLflow Action:** Creates Root Trace\n",
    "```python\n",
    "# MLflow automatically creates a trace\n",
    "trace = {\n",
    "    \"trace_id\": \"tr_xyz123abc\",\n",
    "    \"request_time\": 1732400000000,\n",
    "    \"state\": \"IN_PROGRESS\"\n",
    "}\n",
    "\n",
    "# Creates root span for the predict method\n",
    "root_span = {\n",
    "    \"span_id\": \"sp_001\",\n",
    "    \"name\": \"DocsAgent.predict\",\n",
    "    \"span_type\": \"AGENT\",\n",
    "    \"start_time\": 1732400000000,\n",
    "    \"status\": \"running\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Step 1.2: Message Conversion**\n",
    "```python\n",
    "request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "\n",
    "# After conversion:\n",
    "request = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the latest news on OpenAI product releases? Provide results in bullet points\",\n",
    "            \"type\": \"human\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "**Step 1.3: Agent Invocation**\n",
    "```python\n",
    "output = self.agent.invoke(request)\n",
    "# This triggers the LangGraph execution\n",
    "```\n",
    "\n",
    "### Phase 2: LangGraph Initialization\n",
    "\n",
    "**Code Entry Point:**\n",
    "```python\n",
    "# self.agent is a CompiledGraph created by:\n",
    "agent = create_tool_calling_agent(llm, tools=self.tools)\n",
    "```\n",
    "\n",
    "**What Happens:**\n",
    "\n",
    "**Step 2.1: Graph Receives Request**\n",
    "```python\n",
    "# The compiled graph's invoke method is called\n",
    "compiled_graph.invoke(request)\n",
    "\n",
    "# Initial state is created:\n",
    "initial_state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"What is the latest news on OpenAI product releases?\")\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "**MLflow Action:** Creates Chain Span\n",
    "```python\n",
    "# MLflow creates a span for the graph execution\n",
    "graph_span = {\n",
    "    \"span_id\": \"sp_002\",\n",
    "    \"parent_span_id\": \"sp_001\",\n",
    "    \"name\": \"StateGraph.invoke\",\n",
    "    \"span_type\": \"CHAIN\",\n",
    "    \"start_time\": 1732400000050,\n",
    "    \"inputs\": {\n",
    "        \"messages\": [...]\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Step 2.2: Graph Determines Starting Node**\n",
    "```python\n",
    "# Graph starts at START edge\n",
    "# START edge points to \"tool_calling_llm\" node\n",
    "current_node = \"tool_calling_llm\"\n",
    "```\n",
    "\n",
    "### Phase 3: First LLM Call (Decision Making)\n",
    "\n",
    "**Code Entry Point:**\n",
    "```python\n",
    "def tool_calling_llm(state: ChatAgentState, config: RunnableConfig):\n",
    "    response = model_runnable.invoke(state, config)\n",
    "    return {\"messages\": [response]}\n",
    "```\n",
    "\n",
    "**What Happens:**\n",
    "\n",
    "**Step 3.1: Node Function Called**\n",
    "```python\n",
    "# LangGraph calls the tool_calling_llm function\n",
    "# Parameters:\n",
    "state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"What is the latest news on OpenAI product releases?\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "config = RunnableConfig(\n",
    "    configurable={\n",
    "        \"temperature\": 0.01,\n",
    "        \"max_tokens\": 1000\n",
    "    },\n",
    "    metadata={\n",
    "        \"trace_id\": \"tr_xyz123abc\",\n",
    "        \"span_id\": \"sp_003\"\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "**Step 3.2: Preprocessor Extraction**\n",
    "```python\n",
    "# The preprocessor extracts messages from state\n",
    "preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n",
    "\n",
    "# Execution:\n",
    "messages = preprocessor.invoke(state, config)\n",
    "# Returns: [HumanMessage(content=\"What is the latest news...\")]\n",
    "```\n",
    "\n",
    "**Step 3.3: Model Invocation**\n",
    "```python\n",
    "# model_runnable = preprocessor | llm_with_tools\n",
    "# The pipe (|) chains the operations\n",
    "\n",
    "# First: preprocessor extracts messages\n",
    "extracted_messages = [HumanMessage(content=\"What is the latest news...\")]\n",
    "\n",
    "# Second: llm_with_tools processes the messages\n",
    "response = llm_with_tools.invoke(extracted_messages, config)\n",
    "```\n",
    "\n",
    "**MLflow Action:** Creates LLM Span\n",
    "```python\n",
    "# MLflow creates a span for the LLM call\n",
    "llm_span = {\n",
    "    \"span_id\": \"sp_003\",\n",
    "    \"parent_span_id\": \"sp_002\",\n",
    "    \"name\": \"tool_calling_llm\",\n",
    "    \"span_type\": \"LLM\",\n",
    "    \"start_time\": 1732400000100,\n",
    "    \"inputs\": {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"What is the latest news on OpenAI product releases?\"}\n",
    "        ],\n",
    "        \"model\": \"databricks-meta-llama-3-3-70b-instruct\",\n",
    "        \"temperature\": 0.01,\n",
    "        \"max_tokens\": 1000\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Step 3.4: LLM Processing**\n",
    "```python\n",
    "# The LLM analyzes the request\n",
    "# Internal LLM reasoning (conceptual):\n",
    "# 1. User wants latest news about OpenAI\n",
    "# 2. This requires real-time information\n",
    "# 3. I have access to search_web tool\n",
    "# 4. Decision: Call search_web tool\n",
    "\n",
    "# LLM returns AIMessage with tool_calls\n",
    "response = AIMessage(\n",
    "    content=\"\",  # Empty content when calling tools\n",
    "    tool_calls=[\n",
    "        {\n",
    "            \"name\": \"agentic_ai__databricks__search_web\",\n",
    "            \"args\": {\n",
    "                \"query\": \"OpenAI latest product releases news 2024\"\n",
    "            },\n",
    "            \"id\": \"call_abc123\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "**MLflow Action:** Updates LLM Span\n",
    "```python\n",
    "# MLflow updates the span with outputs and metrics\n",
    "llm_span.update({\n",
    "    \"end_time\": 1732400002750,\n",
    "    \"outputs\": {\n",
    "        \"content\": \"\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"name\": \"agentic_ai__databricks__search_web\",\n",
    "                \"args\": {\"query\": \"OpenAI latest product releases news 2024\"},\n",
    "                \"id\": \"call_abc123\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"attributes\": {\n",
    "        \"mlflow.chat.tokenUsage\": {\n",
    "            \"input_tokens\": 67,\n",
    "            \"output_tokens\": 45,\n",
    "            \"total_tokens\": 112\n",
    "        },\n",
    "        \"execution_time_ms\": 2650,\n",
    "        \"has_tool_calls\": true,\n",
    "        \"tool_call_count\": 1\n",
    "    }\n",
    "})\n",
    "```\n",
    "\n",
    "**Step 3.5: Update State**\n",
    "```python\n",
    "# The node function returns updated messages\n",
    "return {\"messages\": [response]}\n",
    "\n",
    "# State is updated:\n",
    "state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"What is the latest news on OpenAI product releases?\"),\n",
    "        AIMessage(\n",
    "            content=\"\",\n",
    "            tool_calls=[{\n",
    "                \"name\": \"agentic_ai__databricks__search_web\",\n",
    "                \"args\": {\"query\": \"OpenAI latest product releases news 2024\"},\n",
    "                \"id\": \"call_abc123\"\n",
    "            }]\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "### Phase 4: Conditional Routing (Decision Point)\n",
    "\n",
    "**Code Entry Point:**\n",
    "```python\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    tools_condition,  # This function decides the next step\n",
    "    [\"tools\", END]\n",
    ")\n",
    "```\n",
    "\n",
    "**What Happens:**\n",
    "\n",
    "**Step 4.1: tools_condition Evaluation**\n",
    "```python\n",
    "# LangGraph calls tools_condition to decide routing\n",
    "def tools_condition(state):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # Check if last message has tool_calls\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "# Execution:\n",
    "last_message = state[\"messages\"][-1]\n",
    "# last_message is AIMessage with tool_calls\n",
    "\n",
    "# Decision:\n",
    "next_node = \"tools\"  # Route to tools node\n",
    "```\n",
    "\n",
    "**MLflow Action:** Logs Routing Decision\n",
    "```python\n",
    "# MLflow can log the routing decision as span attributes\n",
    "llm_span.set_attributes({\n",
    "    \"routing_decision\": \"tools\",\n",
    "    \"reason\": \"tool_calls_present\"\n",
    "})\n",
    "```\n",
    "\n",
    "**Step 4.2: Graph Routes to Tools Node**\n",
    "```python\n",
    "# LangGraph routes execution to the \"tools\" node\n",
    "current_node = \"tools\"\n",
    "```\n",
    "\n",
    "### Phase 5: Tool Execution\n",
    "\n",
    "**Code Entry Point:**\n",
    "```python\n",
    "builder.add_node(\"tools\", ChatAgentToolNode(tools=tools))\n",
    "```\n",
    "\n",
    "**What Happens:**\n",
    "\n",
    "**Step 5.1: ChatAgentToolNode Initialization**\n",
    "```python\n",
    "# ChatAgentToolNode receives the state\n",
    "tool_node = ChatAgentToolNode(tools=tools)\n",
    "\n",
    "# State contains:\n",
    "state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"What is the latest news...\"),\n",
    "        AIMessage(content=\"\", tool_calls=[...])\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "**Step 5.2: Extract Tool Calls**\n",
    "```python\n",
    "# ChatAgentToolNode extracts tool calls from last message\n",
    "messages = state[\"messages\"]\n",
    "last_message = messages[-1]\n",
    "tool_calls = last_message.tool_calls\n",
    "\n",
    "# Extracted tool call:\n",
    "tool_call = {\n",
    "    \"name\": \"agentic_ai__databricks__search_web\",\n",
    "    \"args\": {\"query\": \"OpenAI latest product releases news 2024\"},\n",
    "    \"id\": \"call_abc123\"\n",
    "}\n",
    "```\n",
    "\n",
    "**MLflow Action:** Creates Tool Span\n",
    "```python\n",
    "# MLflow creates a span for tool execution\n",
    "tool_span = {\n",
    "    \"span_id\": \"sp_004\",\n",
    "    \"parent_span_id\": \"sp_002\",\n",
    "    \"name\": \"search_web\",\n",
    "    \"span_type\": \"TOOL\",\n",
    "    \"start_time\": 1732400002800,\n",
    "    \"inputs\": {\n",
    "        \"tool_name\": \"agentic_ai__databricks__search_web\",\n",
    "        \"tool_input\": {\n",
    "            \"query\": \"OpenAI latest product releases news 2024\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Step 5.3: Find and Execute Tool**\n",
    "```python\n",
    "# Find the matching tool\n",
    "tool_to_execute = None\n",
    "for tool in tools:\n",
    "    if tool.name == \"agentic_ai__databricks__search_web\":\n",
    "        tool_to_execute = tool\n",
    "        break\n",
    "\n",
    "# Execute the tool\n",
    "tool_input = {\"query\": \"OpenAI latest product releases news 2024\"}\n",
    "tool_result = tool_to_execute.invoke(tool_input)\n",
    "\n",
    "# Tool execution (conceptual):\n",
    "# 1. Connect to search API\n",
    "# 2. Query: \"OpenAI latest product releases news 2024\"\n",
    "# 3. Retrieve results\n",
    "# 4. Format and return\n",
    "\n",
    "# Result:\n",
    "tool_result = \"\"\"\n",
    "Recent OpenAI developments include:\n",
    "- GPT-4 Turbo launched with 128K context window for processing longer documents\n",
    "- ChatGPT Enterprise released with advanced security features and admin controls\n",
    "- DALL-E 3 integrated directly into ChatGPT for seamless image generation\n",
    "- Custom GPTs marketplace announced, allowing users to create specialized AI assistants\n",
    "- API improvements with better rate limits and new function calling capabilities\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**MLflow Action:** Updates Tool Span\n",
    "```python\n",
    "# MLflow updates the span with results\n",
    "tool_span.update({\n",
    "    \"end_time\": 1732400006150,\n",
    "    \"outputs\": {\n",
    "        \"content\": \"Recent OpenAI developments include:\\n- GPT-4 Turbo launched with...\"\n",
    "    },\n",
    "    \"attributes\": {\n",
    "        \"mlflow.tool.function_name\": \"agentic_ai.databricks.search_web\",\n",
    "        \"execution_time_ms\": 3350,\n",
    "        \"tool_status\": \"success\",\n",
    "        \"result_length\": 487\n",
    "    }\n",
    "})\n",
    "```\n",
    "\n",
    "**Step 5.4: Create Tool Response Message**\n",
    "```python\n",
    "# ChatAgentToolNode creates a ToolMessage\n",
    "tool_message = ToolMessage(\n",
    "    content=tool_result,\n",
    "    tool_call_id=\"call_abc123\"\n",
    ")\n",
    "\n",
    "# Return updated state\n",
    "return {\"messages\": [tool_message]}\n",
    "```\n",
    "\n",
    "**Step 5.5: Update State**\n",
    "```python\n",
    "# State after tool execution:\n",
    "state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"What is the latest news on OpenAI product releases?\"),\n",
    "        AIMessage(content=\"\", tool_calls=[...]),\n",
    "        ToolMessage(\n",
    "            content=\"Recent OpenAI developments include:\\n- GPT-4 Turbo...\",\n",
    "            tool_call_id=\"call_abc123\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "### Phase 6: Return to LLM (Response Generation)\n",
    "\n",
    "**Code Entry Point:**\n",
    "```python\n",
    "builder.add_edge(\"tools\", \"tool_calling_llm\")\n",
    "# After tools node, always go back to tool_calling_llm\n",
    "```\n",
    "\n",
    "**What Happens:**\n",
    "\n",
    "**Step 6.1: Second LLM Call Initiated**\n",
    "```python\n",
    "# LangGraph routes back to tool_calling_llm node\n",
    "# The same function is called again with updated state\n",
    "\n",
    "def tool_calling_llm(state: ChatAgentState, config: RunnableConfig):\n",
    "    response = model_runnable.invoke(state, config)\n",
    "    return {\"messages\": [response]}\n",
    "```\n",
    "\n",
    "**Step 6.2: State Contains Tool Results**\n",
    "```python\n",
    "# State now has three messages:\n",
    "state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"What is the latest news on OpenAI product releases?\"),\n",
    "        AIMessage(content=\"\", tool_calls=[...]),\n",
    "        ToolMessage(content=\"Recent OpenAI developments include...\")\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "**MLflow Action:** Creates Second LLM Span\n",
    "```python\n",
    "# MLflow creates another LLM span\n",
    "llm_span_2 = {\n",
    "    \"span_id\": \"sp_005\",\n",
    "    \"parent_span_id\": \"sp_002\",\n",
    "    \"name\": \"tool_calling_llm\",\n",
    "    \"span_type\": \"LLM\",\n",
    "    \"start_time\": 1732400006200,\n",
    "    \"inputs\": {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"What is the latest news...\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"\", \"tool_calls\": [...]},\n",
    "            {\"role\": \"tool\", \"content\": \"Recent OpenAI developments...\", \"tool_call_id\": \"call_abc123\"}\n",
    "        ],\n",
    "        \"model\": \"databricks-meta-llama-3-3-70b-instruct\",\n",
    "        \"temperature\": 0.01,\n",
    "        \"max_tokens\": 1000\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Step 6.3: LLM Processes Tool Results**\n",
    "```python\n",
    "# The LLM now has:\n",
    "# 1. Original user question\n",
    "# 2. Its decision to call search_web\n",
    "# 3. The search results\n",
    "\n",
    "# LLM generates final response\n",
    "response = AIMessage(\n",
    "    content=\"\"\"Based on the latest information, here are the recent OpenAI product releases:\n",
    "\n",
    "â€¢ GPT-4 Turbo with 128K context window for processing longer documents and complex tasks\n",
    "â€¢ ChatGPT Enterprise featuring advanced security, admin controls, and priority access\n",
    "â€¢ DALL-E 3 integration enabling users to generate images directly within ChatGPT conversations\n",
    "â€¢ Custom GPTs marketplace where users can create and share specialized AI assistants\n",
    "â€¢ Enhanced API capabilities with improved rate limits and sophisticated function calling features\"\"\",\n",
    "    tool_calls=[]  # No more tool calls needed\n",
    ")\n",
    "```\n",
    "\n",
    "**MLflow Action:** Updates Second LLM Span\n",
    "```python\n",
    "# MLflow updates the span\n",
    "llm_span_2.update({\n",
    "    \"end_time\": 1732400008300,\n",
    "    \"outputs\": {\n",
    "        \"content\": \"Based on the latest information, here are the recent OpenAI product releases:\\n\\nâ€¢ GPT-4 Turbo...\",\n",
    "        \"tool_calls\": []\n",
    "    },\n",
    "    \"attributes\": {\n",
    "        \"mlflow.chat.tokenUsage\": {\n",
    "            \"input_tokens\": 245,\n",
    "            \"output_tokens\": 180,\n",
    "            \"total_tokens\": 425\n",
    "        },\n",
    "        \"execution_time_ms\": 2100,\n",
    "        \"has_tool_calls\": false,\n",
    "        \"response_type\": \"text\"\n",
    "    }\n",
    "})\n",
    "```\n",
    "\n",
    "**Step 6.4: Update State with Final Response**\n",
    "```python\n",
    "return {\"messages\": [response]}\n",
    "\n",
    "# Final state:\n",
    "state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"What is the latest news on OpenAI product releases?\"),\n",
    "        AIMessage(content=\"\", tool_calls=[...]),\n",
    "        ToolMessage(content=\"Recent OpenAI developments...\"),\n",
    "        AIMessage(content=\"Based on the latest information, here are the recent OpenAI product releases:\\n\\nâ€¢ GPT-4 Turbo...\")\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "### Phase 7: Final Routing Decision\n",
    "\n",
    "**Code Entry Point:**\n",
    "```python\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    tools_condition,\n",
    "    [\"tools\", END]\n",
    ")\n",
    "```\n",
    "\n",
    "**What Happens:**\n",
    "\n",
    "**Step 7.1: Evaluate tools_condition Again**\n",
    "```python\n",
    "def tools_condition(state):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # Check for tool_calls\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "# Execution:\n",
    "last_message = AIMessage(content=\"Based on the latest...\", tool_calls=[])\n",
    "# No tool_calls present\n",
    "\n",
    "# Decision:\n",
    "next_node = END  # Terminate execution\n",
    "```\n",
    "\n",
    "**Step 7.2: Graph Execution Completes**\n",
    "```python\n",
    "# LangGraph marks execution as complete\n",
    "execution_status = \"COMPLETED\"\n",
    "```\n",
    "\n",
    "**MLflow Action:** Closes Chain Span\n",
    "```python\n",
    "# MLflow closes the StateGraph span\n",
    "graph_span.update({\n",
    "    \"end_time\": 1732400008350,\n",
    "    \"outputs\": {\n",
    "        \"messages\": [/* all four messages */]\n",
    "    },\n",
    "    \"attributes\": {\n",
    "        \"total_nodes_executed\": 3,\n",
    "        \"total_edges_traversed\": 4,\n",
    "        \"execution_path\": \"START -> tool_calling_llm -> tools -> tool_calling_llm -> END\"\n",
    "    }\n",
    "})\n",
    "```\n",
    "\n",
    "### Phase 8: Response Assembly\n",
    "\n",
    "**Code Entry Point:**\n",
    "```python\n",
    "def predict(...) -> ChatAgentResponse:\n",
    "    request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "    output = self.agent.invoke(request)\n",
    "    return ChatAgentResponse(**output)  # â† We're here\n",
    "```\n",
    "\n",
    "**What Happens:**\n",
    "\n",
    "**Step 8.1: Extract Output**\n",
    "```python\n",
    "# output from agent.invoke():\n",
    "output = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"What is the latest news on OpenAI product releases?\"),\n",
    "        AIMessage(content=\"\", tool_calls=[...]),\n",
    "        ToolMessage(content=\"Recent OpenAI developments...\"),\n",
    "        AIMessage(content=\"Based on the latest information, here are the recent OpenAI product releases:\\n\\nâ€¢ GPT-4 Turbo...\")\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "**Step 8.2: Create ChatAgentResponse**\n",
    "```python\n",
    "# Convert to MLflow's response format\n",
    "response = ChatAgentResponse(**output)\n",
    "\n",
    "# ChatAgentResponse structure:\n",
    "response = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What is the latest news on OpenAI product releases?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"\", \"tool_calls\": [...]},\n",
    "        {\"role\": \"tool\", \"content\": \"Recent OpenAI developments...\", \"tool_call_id\": \"call_abc123\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Based on the latest information, here are the recent OpenAI product releases:\\n\\nâ€¢ GPT-4 Turbo...\"}\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "**MLflow Action:** Closes Root Span\n",
    "```python\n",
    "# MLflow closes the root DocsAgent.predict span\n",
    "root_span.update({\n",
    "    \"end_time\": 1732400008400,\n",
    "    \"outputs\": {\n",
    "        \"messages\": [/* all messages */]\n",
    "    },\n",
    "    \"attributes\": {\n",
    "        \"total_execution_time_ms\": 8400,\n",
    "        \"message_count\": 4,\n",
    "        \"final_message_length\": 456\n",
    "    }\n",
    "})\n",
    "```\n",
    "\n",
    "**Step 8.3: Finalize Trace**\n",
    "```python\n",
    "# MLflow finalizes the trace\n",
    "trace.update({\n",
    "    \"execution_duration\": 8400,\n",
    "    \"state\": \"OK\",\n",
    "    \"response_preview\": \"Based on the latest information, here are the recent OpenAI product releases:\\n\\nâ€¢ GPT-4 Turbo...\",\n",
    "    \"token_usage\": {\n",
    "        \"input_tokens\": 312,\n",
    "        \"output_tokens\": 225,\n",
    "        \"total_tokens\": 537\n",
    "    }\n",
    "})\n",
    "```\n",
    "\n",
    "**Step 8.4: Return to User**\n",
    "```python\n",
    "# The predict method returns\n",
    "return response\n",
    "\n",
    "# User receives:\n",
    "result = ChatAgentResponse(\n",
    "    messages=[\n",
    "        {...},  # All messages\n",
    "        {\"role\": \"assistant\", \"content\": \"Based on the latest information, here are the recent OpenAI product releases:\\n\\nâ€¢ GPT-4 Turbo...\"}\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "## Complete Execution Timeline\n",
    "\n",
    "Here's a visual representation of the entire execution flow:\n",
    "\n",
    "```\n",
    "â±ï¸ Timeline: Total Duration = 8.4 seconds\n",
    "\n",
    "T=0.000s   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "           â”‚ Phase 1: AGENT.predict() called                    â”‚\n",
    "           â”‚ - Create root trace                                 â”‚\n",
    "           â”‚ - Convert messages                                  â”‚\n",
    "           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "T=0.050s   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "           â”‚ Phase 2: LangGraph initialized                      â”‚\n",
    "           â”‚ - Create initial state                              â”‚\n",
    "           â”‚ - Route to START -> tool_calling_llm                â”‚\n",
    "           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "T=0.100s   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "           â”‚ Phase 3: First LLM Call (2.65s)                     â”‚\n",
    "           â”‚ - Extract messages with preprocessor                â”‚\n",
    "T=0.150s   â”‚ - Send to LLM                                       â”‚\n",
    "           â”‚ - LLM analyzes query                                â”‚\n",
    "           â”‚ - LLM decides to call search_web                    â”‚\n",
    "T=2.750s   â”‚ - Return AIMessage with tool_calls                  â”‚\n",
    "           â”‚ - Token usage: 112 (67 input + 45 output)          â”‚\n",
    "           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "T=2.800s   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "           â”‚ Phase 4: Conditional Routing                        â”‚\n",
    "           â”‚ - tools_condition evaluates state                   â”‚\n",
    "           â”‚ - Detects tool_calls present                        â”‚\n",
    "           â”‚ - Routes to \"tools\" node                            â”‚\n",
    "           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "T=2.850s   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "           â”‚ Phase 5: Tool Execution (3.35s)                     â”‚\n",
    "           â”‚ - Extract tool call from AIMessage                  â”‚\n",
    "           â”‚ - Find search_web tool                              â”‚\n",
    "T=3.000s   â”‚ - Execute: search_web(\"OpenAI latest...\")           â”‚\n",
    "           â”‚ - Wait for search results                           â”‚\n",
    "T=6.150s   â”‚ - Return ToolMessage with results                   â”‚\n",
    "           â”‚ - Update state with tool response                   â”‚\n",
    "           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "T=6.200s   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "           â”‚ Phase 6: Second LLM Call (2.10s)                    â”‚\n",
    "           â”‚ - Route back to tool_calling_llm                    â”‚\n",
    "           â”‚ - State now contains tool results                   â”‚\n",
    "T=6.250s   â”‚ - Send complete conversation to LLM                 â”‚\n",
    "           â”‚ - LLM processes tool results                        â”‚\n",
    "           â”‚ - LLM generates formatted response                  â”‚\n",
    "T=8.300s   â”‚ - Return AIMessage with final answer                â”‚\n",
    "           â”‚ - Token usage: 425 (245 input + 180 output)        â”‚\n",
    "           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "T=8.350s   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "           â”‚ Phase 7: Final Routing                              â”‚\n",
    "           â”‚ - tools_condition evaluates state                   â”‚\n",
    "           â”‚ - No tool_calls detected                            â”‚\n",
    "           â”‚ - Routes to END                                     â”‚\n",
    "           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "T=8.400s   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "           â”‚ Phase 8: Response Assembly                          â”‚\n",
    "           â”‚ - Create ChatAgentResponse                          â”‚\n",
    "           â”‚ - Finalize trace and spans                          â”‚\n",
    "           â”‚ - Return to user                                    â”‚\n",
    "           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "ğŸ“Š Final Statistics:\n",
    "   - Total Duration: 8.4 seconds\n",
    "   - Total Tokens: 537\n",
    "   - LLM Calls: 2\n",
    "   - Tool Calls: 1\n",
    "   - Spans Created: 5\n",
    "```\n",
    "\n",
    "## State Evolution Throughout Execution\n",
    "\n",
    "Let's see how the state changes at each phase:\n",
    "\n",
    "```python\n",
    "# Phase 1: Initial State\n",
    "state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"What is the latest news on OpenAI product releases?\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Phase 3: After First LLM Call\n",
    "state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"What is the latest news on OpenAI product releases?\"),\n",
    "        AIMessage(\n",
    "            content=\"\",\n",
    "            tool_calls=[{\n",
    "                \"name\": \"agentic_ai__databricks__search_web\",\n",
    "                \"args\": {\"query\": \"OpenAI latest product releases news 2024\"},\n",
    "                \"id\": \"call_abc123\"\n",
    "            }]\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Phase 5: After Tool Execution\n",
    "state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"What is the latest news on OpenAI product releases?\"),\n",
    "        AIMessage(content=\"\", tool_calls=[...]),\n",
    "        ToolMessage(\n",
    "            content=\"Recent OpenAI developments include:\\n- GPT-4 Turbo launched...\",\n",
    "            tool_call_id=\"call_abc123\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Phase 6: After Second LLM Call (Final State)\n",
    "state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"What is the latest news on OpenAI product releases?\"),\n",
    "        AIMessage(content=\"\", tool_calls=[...]),\n",
    "        ToolMessage(content=\"Recent OpenAI developments...\"),\n",
    "        AIMessage(\n",
    "            content=\"Based on the latest information, here are the recent OpenAI product releases:\\n\\nâ€¢ GPT-4 Turbo with 128K context window...\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "## Key Observations\n",
    "\n",
    "### 1. **Automatic Tracing**\n",
    "MLflow automatically created 5 spans without any manual instrumentation:\n",
    "- 1 Root AGENT span (DocsAgent.predict)\n",
    "- 1 CHAIN span (StateGraph.invoke)\n",
    "- 2 LLM spans (two tool_calling_llm calls)\n",
    "- 1 TOOL span (search_web execution)\n",
    "\n",
    "### 2. **Configuration Flow**\n",
    "The `RunnableConfig` flowed through every step:\n",
    "```python\n",
    "# Started in predict() â†’ \n",
    "# Passed to agent.invoke() â†’ \n",
    "# Propagated to tool_calling_llm() â†’ \n",
    "# Flowed through model_runnable â†’ \n",
    "# Used by LLM for temperature, max_tokens\n",
    "```\n",
    "\n",
    "### 3. **State Management**\n",
    "The `ChatAgentState` accumulated messages:\n",
    "- Started with 1 message (user query)\n",
    "- Added AIMessage with tool_calls\n",
    "- Added ToolMessage with results\n",
    "- Added final AIMessage with answer\n",
    "- Each node could access complete conversation history\n",
    "\n",
    "### 4. **Conditional Routing**\n",
    "The `tools_condition` function made two decisions:\n",
    "- First: Detected tool_calls â†’ routed to \"tools\"\n",
    "- Second: No tool_calls â†’ routed to END\n",
    "\n",
    "### 5. **Token Tracking**\n",
    "MLflow automatically tracked tokens:\n",
    "- First LLM call: 112 tokens (67 input + 45 output)\n",
    "- Second LLM call: 425 tokens (245 input + 180 output)\n",
    "- Total: 537 tokens\n",
    "\n",
    "## Accessing Execution Details\n",
    "\n",
    "After execution, you can analyze the complete flow:\n",
    "\n",
    "```python\n",
    "# Get the trace\n",
    "trace_id = mlflow.get_last_active_trace_id()\n",
    "trace = mlflow.get_trace(trace_id)\n",
    "\n",
    "# Print execution summary\n",
    "print(f\"Total Duration: {trace.info.execution_duration}ms\")\n",
    "print(f\"Total Tokens: {trace.info.token_usage['total_tokens']}\")\n",
    "print(f\"Status: {trace.info.state}\")\n",
    "\n",
    "# Analyze each span\n",
    "print(\"\\n=== Execution Breakdown ===\")\n",
    "for span in trace.data.spans:\n",
    "    duration = span.end_time_unix_ms - span.start_time_unix_ms\n",
    "    print(f\"\\n{span.name} ({span.span_type})\")\n",
    "    print(f\"  Duration: {duration}ms\")\n",
    "    \n",
    "    if span.span_type == \"LLM\":\n",
    "        tokens = span.get_attribute(\"mlflow.chat.tokenUsage\")\n",
    "        print(f\"  Tokens: {tokens['total_tokens']}\")\n",
    "        \n",
    "    if span.span_type == \"TOOL\":\n",
    "        tool_name = span.get_attribute(\"mlflow.tool.function_name\")\n",
    "        print(f\"  Tool: {tool_name}\")\n",
    "\n",
    "# Output:\n",
    "# Total Duration: 8400ms\n",
    "# Total Tokens: 537\n",
    "# Status: OK\n",
    "#\n",
    "# === Execution Breakdown ===\n",
    "#\n",
    "# DocsAgent.predict (AGENT)\n",
    "#   Duration: 8400ms\n",
    "#\n",
    "# StateGraph.invoke (CHAIN)\n",
    "#   Duration: 8300ms\n",
    "#\n",
    "# tool_calling_llm (LLM)\n",
    "#   Duration: 2650ms\n",
    "#   Tokens: 112\n",
    "#\n",
    "# search_web (TOOL)\n",
    "#   Duration: 3350ms\n",
    "#   Tool: agentic_ai.databricks.search_web\n",
    "#\n",
    "# tool_calling_llm (LLM)\n",
    "#   Duration: 2100ms\n",
    "#   Tokens: 425\n",
    "```\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The MLflow-compatible agent execution flow demonstrates:\n",
    "\n",
    "1. **Seamless Integration**: MLflow tracing works automatically without manual instrumentation\n",
    "2. **Complete Observability**: Every step is captured in detailed spans\n",
    "3. **Configuration Propagation**: `RunnableConfig` flows through the entire execution chain\n",
    "4. **State Management**: `ChatAgentState` maintains conversation context throughout\n",
    "5. **Conditional Logic**: The graph dynamically routes based on LLM decisions\n",
    "6. **Token Tracking**: Automatic cost and usage monitoring\n",
    "\n",
    "Understanding this execution flow empowers you to:\n",
    "- Debug issues by identifying exact failure points\n",
    "- Optimize performance by finding bottlenecks\n",
    "- Track costs by monitoring token usage\n",
    "- Improve agent behavior by analyzing decision patterns\n",
    "\n",
    "This deep understanding transforms agent development from guesswork to precision engineering, enabling you to build truly production-ready AI systems.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Takeaway**: The magic of MLflow-compatible agents isn't just in automatic tracingâ€”it's in the complete, transparent view of every decision, every call, and every transformation your agent makes from question to answer.\n",
    "\n",
    "Happy building! ğŸš€"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4. Explain Execution Flow of the Agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
