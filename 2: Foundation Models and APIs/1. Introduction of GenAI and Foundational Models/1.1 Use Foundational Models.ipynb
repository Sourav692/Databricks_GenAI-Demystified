{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4eb2feb2-54cb-46bf-b08c-8723bb44703d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Using Foundation Models on Databricks: A Comprehensive Guide\n",
    "\n",
    "Foundation models have revolutionized how we approach AI and machine learning tasks. Databricks provides a robust platform for querying and deploying these models through their Model Serving infrastructure. This guide breaks down everything you need to know about using foundation models on Databricks.\n",
    "\n",
    "## üéØ What Are Foundation Models on Databricks?\n",
    "\n",
    "Foundation models are large-scale AI models that can be applied to various tasks. Databricks supports both:\n",
    "- **Databricks-hosted models** through Foundation Model APIs\n",
    "- **External models** from providers like OpenAI, Anthropic, and Google\n",
    "- **Unified OpenAI-compatible API** for consistent querying across all models\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Query Options Available\n",
    "\n",
    "Databricks offers multiple methods to interact with foundation models:\n",
    "\n",
    "### 1. **OpenAI Client**\n",
    "- Query endpoints using the familiar OpenAI SDK\n",
    "- Specify the model serving endpoint name as the model input\n",
    "- Supports chat, embeddings, and completions models\n",
    "\n",
    "### 2. **AI Functions (SQL)**\n",
    "- Use `ai_query()` SQL function for direct model inference\n",
    "- Ideal for data analysts working in SQL environments\n",
    "- Seamlessly integrate AI into your data pipelines\n",
    "\n",
    "### 3. **Serving UI**\n",
    "- Web-based interface for testing queries\n",
    "- Insert JSON format input data\n",
    "- Load pre-logged input examples\n",
    "- Perfect for quick experimentation\n",
    "\n",
    "### 4. **REST API**\n",
    "- Standard HTTP API calls\n",
    "- POST to `/serving-endpoints/{name}/invocations`\n",
    "- Programmatic access for production applications\n",
    "\n",
    "### 5. **MLflow Deployments SDK**\n",
    "- Use the `predict()` function\n",
    "- Python-native interface\n",
    "- Integrated with MLflow ecosystem\n",
    "\n",
    "### 6. **Databricks Python SDK**\n",
    "- High-level abstraction over REST API\n",
    "- Automatic authentication handling\n",
    "- Simplified development experience\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Installation & Setup\n",
    "\n",
    "### Package Requirements by Method:\n",
    "\n",
    "**For OpenAI Client:**\n",
    "```python\n",
    "!pip install databricks-sdk[openai]>=0.35.0\n",
    "```\n",
    "\n",
    "**For MLflow Deployments:**\n",
    "```python\n",
    "!pip install mlflow\n",
    "```\n",
    "\n",
    "**For Databricks SDK:**\n",
    "- Pre-installed on Databricks Runtime 13.3 LTS and above\n",
    "- Manual installation required for Runtime 12.2 LTS and below\n",
    "\n",
    "### üîê Authentication Best Practices:\n",
    "- **Production**: Use machine-to-machine OAuth tokens\n",
    "- **Development/Testing**: Use service principal access tokens\n",
    "- Avoid using personal user tokens in production\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ñ Foundation Model Types & Use Cases\n",
    "\n",
    "### 1. **General Purpose (Chat Models)**\n",
    "\n",
    "**Supported Models:**\n",
    "- `databricks-gpt-5-1`, `databricks-gpt-5`, `databricks-gpt-5-mini/nano`\n",
    "- `databricks-gemini-3-pro`, `databricks-gemini-2-5-pro/flash`\n",
    "- `databricks-claude-sonnet-4-5`, `databricks-claude-opus-4-1`\n",
    "- `databricks-llama-4-maverick`, `databricks-meta-llama-3-3-70b-instruct`\n",
    "- External: OpenAI GPT, Anthropic Claude, Google Gemini\n",
    "\n",
    "**Best Use Cases:**\n",
    "- Virtual assistants and chatbots\n",
    "- Customer support automation\n",
    "- Interactive tutoring systems\n",
    "- Multi-turn dialogue applications\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Embeddings Models**\n",
    "\n",
    "**Supported Models:**\n",
    "- `databricks-gte-large-en`\n",
    "- `databricks-bge-large-en`\n",
    "- External: OpenAI, Cohere, Google text embeddings\n",
    "\n",
    "**Best Use Cases:**\n",
    "- Semantic search engines\n",
    "- Retrieval Augmented Generation (RAG)\n",
    "- Topic clustering and classification\n",
    "- Sentiment analysis\n",
    "- Document similarity comparison\n",
    "\n",
    "**Key Benefit:** Transform complex data into compact numerical vectors for efficient comparison and analysis\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Vision Models**\n",
    "\n",
    "**Supported Models:**\n",
    "- GPT-5 series with vision capabilities\n",
    "- Gemini series with vision\n",
    "- Claude series with vision\n",
    "- Gemma-3-12b, Llama-4-maverick\n",
    "\n",
    "**Best Use Cases:**\n",
    "- Object detection and recognition\n",
    "- Image classification and segmentation\n",
    "- Document understanding and OCR\n",
    "- Visual content analysis\n",
    "- Medical imaging analysis\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Reasoning Models**\n",
    "\n",
    "**Supported Models:**\n",
    "- Advanced GPT-5 series\n",
    "- Gemini Pro series\n",
    "- Claude Sonnet and Opus series\n",
    "- Specialized reasoning variants\n",
    "\n",
    "**Best Use Cases:**\n",
    "- Complex code generation\n",
    "- Content creation and summarization\n",
    "- Agent orchestration\n",
    "- Multi-step problem solving\n",
    "- Logical inference tasks\n",
    "\n",
    "**Key Feature:** Simulate human-like logical thinking with explainable decision-making\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Advanced Features\n",
    "\n",
    "### ‚ö° Function Calling\n",
    "- OpenAI-compatible function calling\n",
    "- Available for Foundation Model APIs and external models\n",
    "- Enable models to interact with external tools and APIs\n",
    "- Perfect for building AI agents\n",
    "\n",
    "### üìä Structured Outputs\n",
    "- Enforce specific output formats\n",
    "- JSON schema validation\n",
    "- Available for Foundation Model APIs\n",
    "- Ensures predictable, parseable responses\n",
    "\n",
    "### üíæ Prompt Caching\n",
    "**Supported for Databricks-hosted Claude models**\n",
    "\n",
    "**Cacheable Components:**\n",
    "- Text content in messages\n",
    "- Thinking messages content\n",
    "- Image content blocks\n",
    "- Tool use definitions and results\n",
    "\n",
    "**Cache Control Example:**\n",
    "```json\n",
    "{\n",
    "  \"messages\": [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\n",
    "      \"type\": \"text\",\n",
    "      \"text\": \"What's the date today?\",\n",
    "      \"cache_control\": {\"type\": \"ephemeral\"}\n",
    "    }]\n",
    "  }]\n",
    "}\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- Reduced latency for repeated prompts\n",
    "- Cost optimization for similar queries\n",
    "- Improved performance for RAG applications\n",
    "\n",
    "---\n",
    "\n",
    "## üéÆ AI Playground\n",
    "\n",
    "Interactive chat-like environment for:\n",
    "- Testing and experimenting with LLMs\n",
    "- Comparing different models side-by-side\n",
    "- Prompt engineering and optimization\n",
    "- No code required\n",
    "\n",
    "**Access:** Available directly in your Databricks workspace\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Prerequisites & Requirements\n",
    "\n",
    "### ‚úÖ Must Have:\n",
    "1. Active model serving endpoint\n",
    "2. Databricks workspace in supported region\n",
    "3. Databricks API token (personal access token or service principal)\n",
    "\n",
    "### üåç Regional Availability:\n",
    "- Check Foundation Model APIs supported regions\n",
    "- Verify external models regional support\n",
    "- Ensure your workspace is in compatible region\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Important API Differences\n",
    "\n",
    "### Databricks vs. Anthropic REST API:\n",
    "- **Output field**: `choices` (not `content`)\n",
    "- **Stop reasons**: `stop`, `length`, `tool_calls` (not Anthropic's naming)\n",
    "- **Streaming format**: Consistent chunk format with usage in every chunk\n",
    "- **OpenAI-compatible**: Ensures broader ecosystem compatibility\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Additional Resources & Next Steps\n",
    "\n",
    "### Monitoring & Operations:\n",
    "- Monitor with AI Gateway-enabled inference tables\n",
    "- Deploy batch inference pipelines\n",
    "- Set up model endpoint management\n",
    "\n",
    "### Learning Resources:\n",
    "- Foundation Model APIs documentation\n",
    "- External models integration guides\n",
    "- OpenAI models tutorial\n",
    "- REST API reference documentation\n",
    "\n",
    "### Model Information:\n",
    "- Browse supported Databricks-hosted models\n",
    "- Review acceptable use policies\n",
    "- Check mitigation requirements (OpenAI models)\n",
    "- Understand gen AI model maintenance policy\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Important Notes\n",
    "\n",
    "### Model Retirement Notice:\n",
    "- **Meta-Llama-3.1-405B-Instruct** will be retired:\n",
    "  - February 15, 2026: Pay-per-token workloads\n",
    "  - May 15, 2026: Provisioned throughput workloads\n",
    "- Check documentation for recommended replacement models\n",
    "- Plan migration during deprecation period\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Key Takeaways\n",
    "\n",
    "1. **Flexibility**: Multiple query methods suit different use cases and workflows\n",
    "2. **Compatibility**: OpenAI-compatible API enables easy migration and integration\n",
    "3. **Variety**: Wide range of model types for diverse AI tasks\n",
    "4. **Advanced Features**: Function calling, structured outputs, and prompt caching\n",
    "5. **Enterprise-Ready**: Strong authentication, monitoring, and governance features\n",
    "6. **Unified Platform**: Single interface for both hosted and external models\n",
    "\n",
    "---\n",
    "\n",
    "**Get Started Today**: Set up your model serving endpoint and start querying foundation models through your preferred method. The unified API makes it easy to experiment and move to production quickly.\n",
    "\n",
    "[Source](https://docs.databricks.com/aws/en/machine-learning/model-serving/score-foundation-models)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1.1 Use Foundational Models",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
