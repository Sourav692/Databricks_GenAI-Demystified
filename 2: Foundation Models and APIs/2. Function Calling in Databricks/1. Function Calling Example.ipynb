{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a59f533-505b-4b5f-ade8-e8b7d25d6977",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Function Calling on Databricks: A Comprehensive Guide for AI Applications\n",
    "\n",
    "Function calling has emerged as a powerful capability for controlling Large Language Model (LLM) outputs, enabling them to generate more structured and reliable responses. Databricks has implemented OpenAI-compatible function calling as part of their Foundation Model APIs and external model serving endpoints. Let's explore how this feature works and how you can leverage it in your generative AI applications.\n",
    "\n",
    "## Understanding Function Calling\n",
    "\n",
    "Function calling provides developers with a mechanism to guide LLMs toward producing structured outputs. Rather than having the model execute functions directly, it generates JSON objects that describe how specific functions should be called, allowing developers to maintain control over the actual function execution in their code.\n",
    "\n",
    "### The Basic Workflow\n",
    "\n",
    "The function calling process on Databricks follows a straightforward sequence:\n",
    "\n",
    "1. **Initial Query**: You call the model with your query and define a set of available functions using the `tools` parameter\n",
    "2. **Model Decision**: The model analyzes the query and decides whether to call any defined functions\n",
    "3. **JSON Generation**: If a function call is warranted, the model generates a JSON object adhering to your custom schema\n",
    "4. **Function Execution**: Your code parses the JSON and executes the appropriate function with the provided arguments\n",
    "5. **Response Completion**: The model receives the function results and generates a final summary for the user\n",
    "\n",
    "## Practical Use Cases\n",
    "\n",
    "Function calling shines in several scenarios:\n",
    "\n",
    "- **Intelligent Assistants**: Build assistants that can interact with external APIs, such as `send_email()` or `get_current_weather()`\n",
    "- **Natural Language to API Translation**: Convert user statements like \"Who are my top customers?\" into structured API calls with proper parameters\n",
    "- **Data Processing**: Transform unstructured data into structured formats (though Databricks recommends their structured outputs feature for batch inference tasks)\n",
    "\n",
    "## Supported Models\n",
    "\n",
    "Databricks supports function calling across a wide range of models through two main serving features:\n",
    "\n",
    "### Foundation Model APIs\n",
    "- GPT-5 series (including GPT-5.1, GPT-5 mini, and GPT-5 nano)\n",
    "- Gemini models (3 Pro Preview, 2.5 Pro, 2.5 Flash)\n",
    "- Claude models (Sonnet-4.5, Sonnet-4, Opus-4.1, 3.7-Sonnet)\n",
    "- Meta Llama models (4 Maverick, 3.3-70B-Instruct, 3.1 variants)\n",
    "- GPT OSS models (20B, 120B)\n",
    "- Gemma-3-12B\n",
    "- Qwen3-Next 80B A3B Instruct (Beta)\n",
    "\n",
    "### External Models\n",
    "Multiple versions of GPT-4o, Claude-3 series models (through both Anthropic and AWS Bedrock providers), with some supporting advanced features like Computer Use (beta).\n",
    "\n",
    "## Implementation Example\n",
    "\n",
    "Here's a practical example using the OpenAI SDK with Databricks:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get('YOUR_DATABRICKS_TOKEN'),\n",
    "    base_url=os.environ.get('YOUR_DATABRICKS_BASE_URL')\n",
    ")\n",
    "\n",
    "# Define your function schema\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "\n",
    "# Make the API call\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is the current temperature of Chicago?\"}]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"databricks-meta-llama-3-3-70b-instruct\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "```\n",
    "\n",
    "## Controlling Function Behavior\n",
    "\n",
    "The `tool_choice` parameter offers flexibility in how functions are called:\n",
    "\n",
    "- **\"auto\"** (default): The model decides whether and which functions to call\n",
    "- **\"required\"**: Forces the model to call one or more functions\n",
    "- **Specific function**: Direct the model to call only a particular function\n",
    "- **\"none\"**: Disable function calling entirely\n",
    "\n",
    "## Important Considerations\n",
    "\n",
    "### JSON Schema Guidelines\n",
    "\n",
    "For optimal results, keep your function definitions simple. Databricks supports a subset of JSON schema specifications with these key limitations:\n",
    "\n",
    "- Maximum of 16 keys in your JSON schema\n",
    "- No support for regular expressions (`pattern`)\n",
    "- Avoid complex schema compositions (`anyOf`, `oneOf`, `allOf`)\n",
    "- Simpler, flatter schemas produce better quality outputs\n",
    "\n",
    "### Token Usage and Costs\n",
    "\n",
    "Be aware that function calling uses prompt injection and enhancement techniques, which increase both input and output token consumption. The more tools you define, the higher your input token countâ€”and your costs.\n",
    "\n",
    "### Current Limitations\n",
    "\n",
    "During the Public Preview phase:\n",
    "- The feature is optimized for single-turn function calling\n",
    "- Parallel function calling is not supported\n",
    "- Maximum of 32 functions can be defined in `tools`\n",
    "- For multi-turn scenarios, Claude models are recommended\n",
    "- Provisioned throughput only works on new endpoints\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Databricks provides a comprehensive notebook with detailed function calling examples to help you get started. The feature is available through Foundation Model APIs in specific regions, with region availability varying by model and serving type.\n",
    "\n",
    "Function calling on Databricks represents a significant step forward in building more reliable, structured AI applications. By giving developers greater control over LLM outputs while maintaining the flexibility of natural language interaction, it opens new possibilities for creating sophisticated AI-powered tools and assistants.\n",
    "\n",
    "---\n",
    "\n",
    "*For the most up-to-date information on supported models, regions, and features, consult the official Databricks documentation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5699f4ea-1ff5-4292-bc10-a4d7303368da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install -qq databricks-sdk[openai]>=0.35.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68dbb92b-a171-4bdc-bb84-947ef756c8ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "DATABRICKS_TOKEN = \"\"\n",
    "DATABRICKS_BASE_URL = \"https://fe-vm-agentic-ai.cloud.databricks.com/serving-endpoints\"\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=DATABRICKS_TOKEN,\n",
    "  base_url=DATABRICKS_BASE_URL\n",
    ")\n",
    "\n",
    "tools = [\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"get_current_weather\",\n",
    "      \"description\": \"Get the current weather in a given location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\", \n",
    "            \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "          },\n",
    "          \"unit\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "]\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is the current temperature of Chicago?\"}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"databricks-meta-llama-3-3-70b-instruct\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "print(json.dumps(response.choices[0].message.model_dump()['tool_calls'], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a3a4439-7c3c-46f1-b414-601f633c6877",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3aef78b5-ae1a-4c5d-8189-b7b1b0b7b0a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "resp = response.choices[0].message\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d955ee1-d329-493f-9da3-5a2a251eea66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if resp.tool_calls:\n",
    "    call_args = [c.function.arguments for c in resp.tool_calls]\n",
    "    if len(call_args) == 1:\n",
    "        print(call_args[0])\n",
    "    print(call_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56ff3955-5dad-43ee-867e-d88cf8536c6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "553ace00-d57e-4622-8f18-1d617bc4b75b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b01e0d92-c4b5-492a-8dee-aaeb8ec0d0df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What is the capital of France?\"}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"databricks-meta-llama-3-3-70b-instruct\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01953336-e420-492d-8356-f4c68a785675",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "If the model responding without using any tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24f55d43-b7ba-460d-851d-16dd4f515282",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "resp = response.choices[0].message\n",
    "if resp.tool_calls:\n",
    "    call_args = [c.function.arguments for c in resp.tool_calls]\n",
    "    if len(call_args) == 1:\n",
    "        print(call_args[0])\n",
    "    print(call_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80206b20-325b-42cf-a84f-8220ea6c7370",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9cffda8-8e8f-4838-a9bb-9bf95c89d237",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": "A10",
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "1. Function Calling Example",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
