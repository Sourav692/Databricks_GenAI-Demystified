{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4894d2d-978e-4f07-bc24-07f1c535ebb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "[Structured outputs on Databricks](https://docs.databricks.com/aws/en/machine-learning/model-serving/structured-outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59bdfe4a-d623-4570-8cb0-9e442329d7d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Structured Outputs on Databricks: A Complete Guide to Generating JSON from Foundation Models\n",
    "\n",
    "As generative AI applications become more sophisticated, the need to extract structured, actionable data from language models has become critical. Databricks has introduced **Structured Outputs**, a powerful feature that enables developers to generate JSON objects that conform to specific schemas directly from foundation models. This capability is transforming how organizations process unstructured data and build robust AI pipelines.\n",
    "\n",
    "## What Are Structured Outputs?\n",
    "\n",
    "Structured outputs provide a mechanism to generate structured data in JSON format from your input data. Unlike traditional language model responses that return free-form text, structured outputs ensure that the model's response adheres to a predefined format or schema.\n",
    "\n",
    "This feature supports three primary output formats:\n",
    "\n",
    "1. **Plain text** - Traditional unstructured text responses\n",
    "2. **Unstructured JSON objects** - JSON output without schema enforcement\n",
    "3. **Schema-validated JSON objects** - JSON that strictly adheres to a specified JSON schema\n",
    "\n",
    "Structured outputs work with OpenAI-compatible models served through Databricks' Foundation Model APIs, available on both pay-per-token and provisioned throughput endpoints.\n",
    "\n",
    "## Why Use Structured Outputs?\n",
    "\n",
    "Databricks recommends structured outputs for several high-value use cases:\n",
    "\n",
    "### 1. **Document Data Extraction**\n",
    "Extract and classify information from large document collections. For example, automatically identifying and categorizing product review feedback as negative, positive, or neutral at scale.\n",
    "\n",
    "### 2. **Batch Inference with Format Requirements**\n",
    "When processing large volumes of data that need consistent output formatting, structured outputs ensure every response matches your downstream system requirements.\n",
    "\n",
    "### 3. **Data Transformation Pipelines**\n",
    "Convert unstructured data into structured formats for analytics, database ingestion, or further processing. This is particularly valuable for building data lakes and warehouses from diverse sources.\n",
    "\n",
    "## How to Implement Structured Outputs\n",
    "\n",
    "Implementing structured outputs is straightforward using the `response_format` parameter in your chat requests. Let's explore two common scenarios.\n",
    "\n",
    "### Example 1: Research Paper Data Extraction\n",
    "\n",
    "This example demonstrates extracting structured information from research papers using a predefined JSON schema:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "DATABRICKS_TOKEN = os.environ.get('YOUR_DATABRICKS_TOKEN')\n",
    "DATABRICKS_BASE_URL = os.environ.get('YOUR_DATABRICKS_BASE_URL')\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=DATABRICKS_TOKEN,\n",
    "    base_url=DATABRICKS_BASE_URL\n",
    ")\n",
    "\n",
    "response_format = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"research_paper_extraction\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"title\": {\"type\": \"string\"},\n",
    "                \"authors\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"abstract\": {\"type\": \"string\"},\n",
    "                \"keywords\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"}\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an expert at structured data extraction. You will be given unstructured text from a research paper and should convert it into the given structure.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"...\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"databricks-gpt-oss-20b\",\n",
    "    messages=messages,\n",
    "    response_format=response_format\n",
    ")\n",
    "\n",
    "print(json.dumps(response.choices[0].message.model_dump()['content'], indent=2))\n",
    "```\n",
    "\n",
    "This approach ensures that every research paper processed returns data in exactly the same format, making it easy to build databases of academic literature.\n",
    "\n",
    "### Example 2: Flexible JSON Extraction\n",
    "\n",
    "When you need JSON output but don't know the exact schema beforehand, you can use the `json_object` type:\n",
    "\n",
    "```python\n",
    "response_format = {\n",
    "    \"type\": \"json_object\",\n",
    "}\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Extract the name, size, price, and color from this product description as a JSON object:\n",
    "<description>\n",
    "The SmartHome Mini is a compact smart home assistant available in black or white for only $49.99. It's 5 inches wide.\n",
    "</description>\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"databricks-gpt-oss-20b\",\n",
    "    messages=messages,\n",
    "    response_format=response_format\n",
    ")\n",
    "\n",
    "print(json.dumps(response.choices[0].message.model_dump()['content'], indent=2))\n",
    "```\n",
    "\n",
    "This flexibility is perfect for exploratory analysis or when working with diverse data sources.\n",
    "\n",
    "## JSON Schema Support and Constraints\n",
    "\n",
    "Databricks Foundation Model APIs support a subset of the [JSON Schema specification](https://json-schema.org/specification) optimized for high-quality generation. To achieve the best results, it's recommended to use simpler schema definitions.\n",
    "\n",
    "### Unsupported Features\n",
    "\n",
    "The following JSON schema features are **not supported**:\n",
    "\n",
    "- **Regular expressions** using `pattern`\n",
    "- **Complex schema composition** using `anyOf`, `oneOf`, `allOf`, `prefixItems`, or `$ref`\n",
    "- **Lists of types** except for the special case of `[type, \"null\"]` where one type is valid and the other is `null`\n",
    "\n",
    "These constraints exist to ensure reliable, high-quality JSON generation without unnecessary complexity.\n",
    "\n",
    "## Important Considerations\n",
    "\n",
    "### Token Usage and Billing\n",
    "\n",
    "Behind the scenes, Databricks uses prompt injection and other optimization techniques to enhance the quality of structured outputs. These techniques impact both input and output token consumption, which affects billing. When planning your implementation, factor in these additional token costs.\n",
    "\n",
    "### Limitations to Keep in Mind\n",
    "\n",
    "1. **Maximum Schema Keys**: The JSON schema can contain a maximum of **64 keys**\n",
    "2. **No Size Constraints**: Foundation Model APIs don't enforce length or size limits using keywords like `maxProperties`, `minProperties`, or `maxLength`\n",
    "3. **Nested Schema Complexity**: Heavily nested JSON schemas can result in lower-quality generation. When possible, flatten your schema for better results\n",
    "4. **Anthropic Claude Models**: These models only accept `json_schema` structured outputs; `json_object` is not supported\n",
    "\n",
    "## Best Practices for Implementation\n",
    "\n",
    "Based on the capabilities and constraints, here are some recommendations:\n",
    "\n",
    "1. **Start Simple**: Begin with straightforward schemas and add complexity only as needed\n",
    "2. **Flatten When Possible**: Avoid deep nesting in your JSON schemas to improve output quality\n",
    "3. **Monitor Token Usage**: Track your token consumption to optimize costs, especially for high-volume applications\n",
    "4. **Test Thoroughly**: Validate that your schema definitions produce the expected results across various inputs\n",
    "5. **Choose the Right Format**: Use `json_schema` for strict validation requirements and `json_object` for flexible extraction tasks\n",
    "\n",
    "## Real-World Applications\n",
    "\n",
    "The potential applications of structured outputs are vast:\n",
    "\n",
    "- **Customer Service**: Automatically categorize and route support tickets based on sentiment and topic\n",
    "- **Legal Document Processing**: Extract key clauses, parties, and dates from contracts\n",
    "- **Medical Records**: Structure patient information from clinical notes\n",
    "- **Market Research**: Transform survey responses into standardized data formats\n",
    "- **Content Moderation**: Classify and flag content according to predefined categories\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Structured outputs on Databricks represent a significant advancement in making foundation models more practical for enterprise applications. By ensuring consistent, schema-validated JSON output, organizations can build more reliable data pipelines and AI-powered workflows.\n",
    "\n",
    "Whether you're extracting insights from documents, transforming unstructured data, or building complex AI applications, structured outputs provide the reliability and consistency needed for production systems. As you implement this feature, remember to balance schema complexity with output quality, and always monitor token usage to optimize costs.\n",
    "\n",
    "With this capability now available on Databricks Foundation Model APIs, data engineers and AI practitioners have a powerful new tool for bridging the gap between unstructured language model outputs and structured data requirements.\n",
    "\n",
    "---\n",
    "\n",
    "*To learn more about structured outputs and other Databricks AI capabilities, visit the [Databricks documentation](https://docs.databricks.com/aws/en/machine-learning/model-serving/structured-outputs).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b30863b-e8d6-487c-8edd-8c321e9d346e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data extraction of research papers to a specific JSON schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bef1955b-e7f7-4c75-b0dc-992b23fc9ecf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -qq openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b18ecf9-7de0-498a-90f0-95524dad157a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6d170e0-6e2a-46d9-9045-7def6f97cd6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "DATABRICKS_TOKEN = \"\"\n",
    "DATABRICKS_BASE_URL = \"https://fe-vm-agentic-ai.cloud.databricks.com/serving-endpoints\"\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=DATABRICKS_TOKEN,\n",
    "  base_url=DATABRICKS_BASE_URL\n",
    "  )\n",
    "\n",
    "response_format = {\n",
    "      \"type\": \"json_schema\",\n",
    "      \"json_schema\": {\n",
    "        \"name\": \"research_paper_extraction\",\n",
    "        \"schema\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"title\": { \"type\": \"string\" },\n",
    "            \"authors\": {\n",
    "              \"type\": \"array\",\n",
    "              \"items\": { \"type\": \"string\" }\n",
    "            },\n",
    "            \"abstract\": { \"type\": \"string\" },\n",
    "            \"keywords\": {\n",
    "              \"type\": \"array\",\n",
    "              \"items\": { \"type\": \"string\" }\n",
    "            }\n",
    "          },\n",
    "        },\n",
    "        \"strict\": True\n",
    "      }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "184c9c16-7850-4cdc-a118-64d78ec26c08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Unstructured research paper content (messy, real-world format)\n",
    "unstructured_paper_text = \"\"\"\n",
    "Proceedings of the International Conference on Machine Learning and Data Science 2024\n",
    "\n",
    "Real-Time Anomaly Detection in IoT Networks using Deep Learning: A Hybrid CNN-LSTM Approach\n",
    "\n",
    "Sarah Chen¹, Michael Rodriguez², Dr. Priya Patel¹, James Thompson³\n",
    "\n",
    "¹University of California, Berkeley - Department of Computer Science\n",
    "²Stanford Research Institute  \n",
    "³Microsoft Research Labs\n",
    "\n",
    "Received: March 15, 2024 | Accepted: August 22, 2024 | Published: September 10, 2024\n",
    "\n",
    "INTRODUCTION AND BACKGROUND\n",
    "\n",
    "The Internet of Things (IoT) has revolutionized how we interact with technology, with an estimated 75 billion connected devices expected by 2025. However, this exponential growth brings unprecedented security challenges. Traditional signature-based intrusion detection systems are inadequate for the dynamic and heterogeneous nature of IoT environments.\n",
    "\n",
    "METHODOLOGY AND APPROACH\n",
    "\n",
    "In this work, we propose a novel hybrid architecture that combines the spatial feature extraction capabilities of Convolutional Neural Networks with the temporal modeling strengths of Long Short-Term Memory networks. Our approach processes network traffic data in real-time, analyzing packet headers, payload characteristics, and temporal patterns to identify anomalous behavior.\n",
    "\n",
    "EXPERIMENTAL SETUP\n",
    "\n",
    "We collected network traffic data from smart home environments including smart thermostats, security cameras, voice assistants, and lighting systems. The dataset comprised 2.5 million network packets gathered over a six-month period from January to June 2024. Data preprocessing involved feature normalization, sequence padding, and splitting into training (70%), validation (15%), and testing (15%) sets.\n",
    "\n",
    "RESULTS AND FINDINGS\n",
    "\n",
    "Our hybrid CNN-LSTM model achieved remarkable performance metrics: 94.7% detection accuracy, 2.1% false positive rate, and 15 milliseconds average response time. When compared to traditional rule-based systems, our approach showed 23% improvement in accuracy and 67% reduction in false alarms. The model successfully detected various attack types including DDoS, man-in-the-middle attacks, and device hijacking attempts.\n",
    "\n",
    "CONCLUSION\n",
    "\n",
    "This research demonstrates that deep learning techniques, specifically the combination of CNN and LSTM architectures, provide a robust solution for real-time IoT anomaly detection. The system's low latency and high accuracy make it suitable for deployment in production environments where immediate threat response is critical.\n",
    "\n",
    "Related research areas include: deep learning applications, anomaly detection algorithms, IoT security frameworks, neural network architectures, real-time processing systems, cybersecurity solutions, machine learning for network security, and network traffic analysis techniques.\n",
    "\n",
    "© 2024 International Conference on Machine Learning and Data Science. All rights reserved.\n",
    "DOI: 10.1234/icmlds.2024.5678\n",
    "Page 142-158\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b1e42f4-e9dd-44d3-b5f9-3d1ae7711441",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "messages = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an expert at structured data extraction. You will be given unstructured text from a research paper and should convert it into the given structure.\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": unstructured_paper_text\n",
    "      }]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"databricks-meta-llama-3-3-70b-instruct\",\n",
    "    messages=messages,\n",
    "    response_format=response_format\n",
    ")\n",
    "\n",
    "print(json.dumps(response.choices[0].message.model_dump()['content'], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3518429e-1bd8-4cd4-88b9-c4bf4eb70256",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0e9df8c-6e12-4708-8054-d1c5321ed032",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "response_format = {\n",
    "      \"type\": \"json_object\",\n",
    "    }\n",
    "\n",
    "messages = [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Extract the name, size, price, and color from this product description as a JSON object:\\n<description>\\nThe SmartHome Mini is a compact smart home assistant available in black or white for only $49.99. It's 5 inches wide.\\n</description>\"\n",
    "      }]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"databricks-meta-llama-3-3-70b-instruct\",\n",
    "    messages=messages,\n",
    "    response_format=response_format\n",
    ")\n",
    "\n",
    "print(json.dumps(response.choices[0].message.model_dump()['content'], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9374dcfb-32ff-4c6c-bc5c-256726aee4ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb7f2819-a173-43b3-97c0-6ecc979d5092",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(response.choices[0].message.model_dump()['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df5147f2-9cbd-4883-aea0-4ef5e35c2139",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": "A10",
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Sample Notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
