{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae2ef0d2-0c53-45d3-9b2f-281ac1bcd43d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Mosaic AI Agent Framework: Author and deploy a multi-agent system with Genie and Serving Endpoints\n",
    "\n",
    "This notebook demonstrates how to build a multi-agent system using Mosaic AI Agent Framework and [LangGraph](https://blog.langchain.dev/langgraph-multi-agent-workflows/), where [Genie](https://www.databricks.com/product/ai-bi/genie) is one of the agents.\n",
    "In this notebook, you:\n",
    "1. Author a multi-agent system using LangGraph.\n",
    "1. Wrap the LangGraph agent with MLflow `ResponsesAgent` to ensure compatibility with Databricks features.\n",
    "1. Manually test the multi-agent system's output.\n",
    "1. Log and deploy the multi-agent system.\n",
    "\n",
    "This example is based on [LangGraph documentation - Multi-agent supervisor example](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/multi_agent/agent_supervisor.md)\n",
    "\n",
    "## Why use a Genie agent?\n",
    "\n",
    "Multi-agent systems consist of multiple AI agents working together, each with specialized capabilities. As one of those agents, Genie allows users to interact with their structured data using natural language. Unlike SQL functions which can only run pre-defined queries, Genie has the flexibility to create novel queries to answer user questions.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Address all `TODO`s in this notebook.\n",
    "- Create a Genie Space, see Databricks documentation ([AWS](https://docs.databricks.com/aws/genie/set-up) | [Azure](https://learn.microsoft.com/azure/databricks/genie/set-up))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fad5bdf5-8ab6-40ad-8b7f-71589b07dde4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqq mlflow-skinny[databricks] databricks-langchain databricks-agents uv langgraph-supervisor==0.0.29\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d402207-8884-456d-8e29-dce582e48dd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Define the multi-agent system\n",
    "\n",
    "Create a multi-agent system in LangGraph using a supervisor agent node with one or more of the following subagents:\n",
    "- **GenieAgent**: A LangChain runnable that allows you to easily interact with your Genie Space to query structured data.\n",
    "- **Custom serving agent**: An agent that is already hosted as an existing endpoint on Databricks.\n",
    "- **In-code tool-calling agent**: An agent that calls Unity Catalog function tools, defined within this notebook. This example uses `system.ai.python_exec`, but for examples of other tools you can add to your agents, see Databricks documentation ([AWS](https://docs.databricks.com/aws/generative-ai/agent-framework/agent-tool) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/agent-framework/agent-tool)).\n",
    "\n",
    "The supervisor agent is responsible for creating and routing tool calls to each of your subagents, passing only the context necessary. You can modify this behavior and pass along the entire message history if desired. See the [LangGraph docs](https://langchain-ai.github.io/langgraph/reference/supervisor/) for more information.\n",
    "\n",
    "#### Write agent code to file\n",
    "\n",
    "Define the agent code in a single cell below. This lets you write the agent code to a local Python file, using the `%%writefile` magic command, for subsequent logging and deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a89ad7a6-599d-46a9-9f09-b149e4651c87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile agent.py\n",
    "import json\n",
    "from typing import Any, Generator, Literal\n",
    "from uuid import uuid4\n",
    "\n",
    "import mlflow\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "from databricks_langchain.genie import GenieAgent\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.runnables import Runnable\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph_supervisor import create_supervisor\n",
    "from mlflow.pyfunc import ResponsesAgent\n",
    "from mlflow.types.responses import (\n",
    "    ResponsesAgentRequest,\n",
    "    ResponsesAgentResponse,\n",
    "    ResponsesAgentStreamEvent,\n",
    ")\n",
    "from pydantic import BaseModel, model_validator\n",
    "\n",
    "client = DatabricksFunctionClient()\n",
    "set_uc_function_client(client)\n",
    "\n",
    "########################################\n",
    "# Create your LangGraph Supervisor Agent\n",
    "########################################\n",
    "\n",
    "GENIE = \"genie\"\n",
    "\n",
    "\n",
    "class ServedSubAgent(BaseModel):\n",
    "    endpoint_name: str\n",
    "    name: str\n",
    "    task: Literal[\"agent/v1/responses\", \"agent/v1/chat\", \"agent/v2/chat\"]\n",
    "    description: str\n",
    "\n",
    "\n",
    "class Genie(BaseModel):\n",
    "    space_id: str\n",
    "    name: str\n",
    "    task: str = GENIE\n",
    "    description: str\n",
    "\n",
    "\n",
    "\n",
    "class InCodeSubAgent(BaseModel):\n",
    "    tools: list[str]\n",
    "    name: str\n",
    "    description: str\n",
    "\n",
    "\n",
    "TOOLS = []\n",
    "\n",
    "def stringify_content(state):\n",
    "    msgs = state[\"messages\"]\n",
    "    if isinstance(msgs[-1].content, list):\n",
    "        msgs[-1].content = json.dumps(msgs[-1].content, indent=4)\n",
    "    return {\"messages\": msgs}\n",
    "\n",
    "\n",
    "def create_langgraph_supervisor(\n",
    "    llm: Runnable,\n",
    "    externally_served_agents: list[ServedSubAgent] = [],\n",
    "    in_code_agents: list[InCodeSubAgent] = [],\n",
    "):\n",
    "    agents = []\n",
    "    agent_descriptions = \"\"\n",
    "\n",
    "    # Process inline code agents\n",
    "    for agent in in_code_agents:\n",
    "        agent_descriptions += f\"- {agent.name}: {agent.description}\\n\"\n",
    "        uc_toolkit = UCFunctionToolkit(function_names=agent.tools)\n",
    "        TOOLS.extend(uc_toolkit.tools)\n",
    "        agents.append(create_react_agent(llm, tools=uc_toolkit.tools, name=agent.name))\n",
    "\n",
    "    # Process served endpoints and Genie Spaces\n",
    "    for agent in externally_served_agents:\n",
    "        agent_descriptions += f\"- {agent.name}: {agent.description}\\n\"\n",
    "        if isinstance(agent, Genie):\n",
    "            genie_agent = GenieAgent(\n",
    "                genie_space_id=agent.space_id,\n",
    "                genie_agent_name=agent.name,\n",
    "                description=agent.description,\n",
    "            )\n",
    "            genie_agent.name = agent.name\n",
    "            agents.append(genie_agent)\n",
    "        else:\n",
    "            model = ChatDatabricks(\n",
    "                endpoint=agent.endpoint_name, use_responses_api=\"responses\" in agent.task\n",
    "            )\n",
    "            # Disable streaming for subagents for ease of parsing\n",
    "            model._stream = lambda x: model._stream(**x, stream=False)\n",
    "            agents.append(\n",
    "                create_react_agent(\n",
    "                    model,\n",
    "                    tools=[],\n",
    "                    name=agent.name,\n",
    "                    post_model_hook=stringify_content,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # TODO: The supervisor prompt includes agent names/descriptions as well as general\n",
    "    # instructions. You can modify this to improve quality or provide custom instructions.\n",
    "    prompt = f\"You are a supervisor in a multi-agent system. If you have enough information based on the chat history to answer the user's query, provide a summarized response to the query, even if it's been answered before. If you still need more information, route requests to the appropriate sub-agent:\\n{agent_descriptions}\"\n",
    "\n",
    "    return create_supervisor(\n",
    "        agents=agents,\n",
    "        model=llm,\n",
    "        prompt=prompt,\n",
    "        add_handoff_messages=True,\n",
    "    ).compile()\n",
    "\n",
    "\n",
    "##########################################\n",
    "# Wrap LangGraph Supervisor as a ResponsesAgent\n",
    "##########################################\n",
    "\n",
    "\n",
    "class LangGraphResponsesAgent(ResponsesAgent):\n",
    "    def __init__(self, agent: CompiledStateGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    def _langchain_to_responses(self, message: BaseMessage) -> list[dict[str, Any]]:\n",
    "        \"Convert from ChatCompletion dict to Responses output item dictionaries. Ignore user and human messages\"\n",
    "        message = message.model_dump()\n",
    "        role = message[\"type\"]\n",
    "        output = []\n",
    "        if role == \"ai\":\n",
    "            if message.get(\"content\"):\n",
    "                output.append(\n",
    "                    self.create_text_output_item(\n",
    "                        text=message[\"content\"],\n",
    "                        id=message.get(\"id\") or str(uuid4()),\n",
    "                    )\n",
    "                )\n",
    "            if tool_calls := message.get(\"tool_calls\"):\n",
    "                output.extend(\n",
    "                    [\n",
    "                        self.create_function_call_item(\n",
    "                            id=message.get(\"id\") or str(uuid4()),\n",
    "                            call_id=tool_call[\"id\"],\n",
    "                            name=tool_call[\"name\"],\n",
    "                            arguments=json.dumps(tool_call[\"args\"]),\n",
    "                        )\n",
    "                        for tool_call in tool_calls\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        elif role == \"tool\":\n",
    "            output.append(\n",
    "                self.create_function_call_output_item(\n",
    "                    call_id=message[\"tool_call_id\"],\n",
    "                    output=message[\"content\"],\n",
    "                )\n",
    "            )\n",
    "        elif role == \"user\" or \"human\":\n",
    "            pass\n",
    "        return output\n",
    "\n",
    "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
    "        outputs = [\n",
    "            event.item\n",
    "            for event in self.predict_stream(request)\n",
    "            if event.type == \"response.output_item.done\"\n",
    "        ]\n",
    "        return ResponsesAgentResponse(output=outputs, custom_outputs=request.custom_inputs)\n",
    "\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        request: ResponsesAgentRequest,\n",
    "    ) -> Generator[ResponsesAgentStreamEvent, None, None]:\n",
    "        cc_msgs = self.prep_msgs_for_cc_llm([i.model_dump() for i in request.input])\n",
    "        first_name = True\n",
    "        seen_ids = set()\n",
    "\n",
    "        for event_name, events in self.agent.stream({\"messages\": cc_msgs}, stream_mode=[\"updates\"]):\n",
    "            if event_name == \"updates\":\n",
    "                if not first_name:\n",
    "                    node_name = tuple(events.keys())[0]  # assumes one name per node\n",
    "                    yield ResponsesAgentStreamEvent(\n",
    "                        type=\"response.output_item.done\",\n",
    "                        item=self.create_text_output_item(\n",
    "                            text=f\"<name>{node_name}</name>\",\n",
    "                            id=str(uuid4()),\n",
    "                        ),\n",
    "                    )\n",
    "                for node_data in events.values():\n",
    "                    for msg in node_data[\"messages\"]:\n",
    "                        if msg.id not in seen_ids:\n",
    "                            print(msg.id, msg)\n",
    "                            seen_ids.add(msg.id)\n",
    "                            for item in self._langchain_to_responses(msg):\n",
    "                                yield ResponsesAgentStreamEvent(\n",
    "                                    type=\"response.output_item.done\", item=item\n",
    "                                )\n",
    "            first_name = False\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# Configure the Foundation Model and Serving Sub-Agents\n",
    "#######################################################\n",
    "\n",
    "# TODO: Replace with your model serving endpoint\n",
    "LLM_ENDPOINT_NAME = \"databricks-claude-3-7-sonnet\"\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "# TODO: Add the necessary information about each of your serving/Genie Space subagents\n",
    "# in the list below, following the examples.\n",
    "#  - Your agent descriptions are crucial for improving quality. Include as much detail as possible.\n",
    "EXTERNALLY_SERVED_AGENTS = [\n",
    "    Genie(\n",
    "        space_id=\"01f0939cca1c1a1d87e507943f57333a\",\n",
    "        name=\"revenue-genie\",\n",
    "        description=\"This agent can answer questions about revenue related to the top 10 companies in the S&P 500.\",\n",
    "    ),\n",
    "    # ServedSubAgent(\n",
    "    #     endpoint_name=\"cities-agent\",\n",
    "    #     name=\"city-agent\", # choose a semantically relevant name for your agent\n",
    "    #     task=\"agent/v1/responses\",\n",
    "    #     description=\"This agent can answer questions about the best cities to visit in the world.\",\n",
    "    # ),\n",
    "]\n",
    "\n",
    "############################################################\n",
    "# Create additional agents in code\n",
    "############################################################\n",
    "\n",
    "# TODO: Fill the following with UC function-calling agents. The tools parameter is a list of UC function names that you want your agent to call.\n",
    "IN_CODE_AGENTS = [\n",
    "    InCodeSubAgent(\n",
    "        tools=[\"system.ai.*\"],\n",
    "        name=\"code execution agent\",\n",
    "        description=\"The code execution agent specializes in solving programming challenges, generating code snippets, debugging issues, and explaining complex coding concepts.\",\n",
    "    )\n",
    "]\n",
    "\n",
    "#################################################\n",
    "# Create supervisor and set up MLflow for tracing\n",
    "#################################################\n",
    "\n",
    "supervisor = create_langgraph_supervisor(llm, EXTERNALLY_SERVED_AGENTS, IN_CODE_AGENTS)\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "AGENT = LangGraphResponsesAgent(supervisor)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0103f4c-4a1f-40ca-9f3d-28bcd1803ec2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the agent\n",
    "\n",
    "Interact with the agent to test its output. Since this notebook called `mlflow.langchain.autolog()` you can view the trace for each step the agent takes.\n",
    "\n",
    "**Important:** LangGraph internally uses exceptions (something like `Command` or `ParentCommand`) to switch between nodes. These particular exceptions may appear in your MLflow traces as Events, but this behavior is expected and should not be a cause for concern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11079f06-9837-4208-af79-2d910058cf2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2964b0a-4a73-41ee-8b41-0bd8ff8b8ac9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from agent import AGENT\n",
    "\n",
    "# TODO: Replace this placeholder `input_example` with a domain-specific prompt for your agent.\n",
    "input_example = {\"input\": [{\"role\": \"user\", \"content\": \"Which companies do I have revenue data for\"}]}\n",
    "\n",
    "AGENT.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af022e19-a090-41fa-9c9a-d64c43ca334f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for event in AGENT.predict_stream(input_example):\n",
    "  print(event.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "299790ba-cd17-4f11-babc-1bc6d3c18cc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log the agent as an MLflow model\n",
    "\n",
    "Log the agent as code from the `agent.py` file. See [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code).\n",
    "\n",
    "### Enable automatic authentication for Databricks resources\n",
    "For the most common Databricks resource types, Databricks supports and recommends declaring resource dependencies for the agent upfront during logging. This enables automatic authentication passthrough when you deploy the agent. With automatic authentication passthrough, Databricks automatically provisions, rotates, and manages short-lived credentials to securely access these resource dependencies from within the agent endpoint.\n",
    "\n",
    "To enable automatic authentication, specify the dependent Databricks resources when calling `mlflow.pyfunc.log_model().`\n",
    "  - **TODO**: If your Unity Catalog tool queries a [vector search index](docs link) or leverages [external functions](docs link), you need to include the dependent vector search index and UC connection objects, respectively, as resources. See docs ([AWS](https://docs.databricks.com/aws/generative-ai/agent-framework/agent-authentication#supported-resources-for-automatic-authentication-passthrough) | [Azure](https://docs.databricks.com/aws/generative-ai/agent-framework/agent-authentication#supported-resources-for-automatic-authentication-passthrough)).\n",
    "\n",
    "  - **TODO**: Add the SQL Warehouse or tables powering your Genie space to enable passthrough authentication. ([AWS](https://docs.databricks.com/aws/generative-ai/agent-framework/agent-authentication#supported-resources-for-automatic-authentication-passthrough) | [Azure](https://docs.databricks.com/aws/generative-ai/agent-framework/agent-authentication#supported-resources-for-automatic-authentication-passthrough)). If your genie space uses \"embedded credentials\" then you do not have to add this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54a7fdf0-d9a1-4d5b-ab3e-2044da70eaa1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "import mlflow\n",
    "from agent import EXTERNALLY_SERVED_AGENTS, LLM_ENDPOINT_NAME, TOOLS, Genie\n",
    "from databricks_langchain import UnityCatalogTool, VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import (\n",
    "    DatabricksFunction,\n",
    "    DatabricksGenieSpace,\n",
    "    DatabricksServingEndpoint,\n",
    "    DatabricksSQLWarehouse,\n",
    "    DatabricksTable\n",
    ")\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "# TODO: Manually include underlying resources if needed. See the TODO in the markdown above for more information.\n",
    "resources = [DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME)]\n",
    "# TODO: Add SQL Warehouses and delta tables powering the Genie Space\n",
    "resources.append(DatabricksSQLWarehouse(warehouse_id=\"\"))\n",
    "resources.append(DatabricksTable(table_name=\"\"))\n",
    "\n",
    "# Add tools from Unity Catalog\n",
    "for tool in TOOLS:\n",
    "    if isinstance(tool, VectorSearchRetrieverTool):\n",
    "        resources.extend(tool.resources)\n",
    "    elif isinstance(tool, UnityCatalogTool):\n",
    "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "# Add serving endpoints and Genie Spaces\n",
    "for agent in EXTERNALLY_SERVED_AGENTS:\n",
    "    if isinstance(agent, Genie):\n",
    "        resources.append(DatabricksGenieSpace(genie_space_id=agent.space_id))\n",
    "    else:\n",
    "        resources.append(DatabricksServingEndpoint(endpoint_name=agent.endpoint_name))\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        resources=resources,\n",
    "        pip_requirements=[\n",
    "            f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n",
    "            f\"mlflow=={get_distribution('mlflow').version}\",\n",
    "            f\"databricks-langchain=={get_distribution('databricks-langchain').version}\",\n",
    "            f\"langgraph=={get_distribution('langgraph').version}\",\n",
    "            f\"langgraph-supervisor=={get_distribution('langgraph-supervisor').version}\",\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "136c836c-8344-4817-80cd-cfbc3f2df3d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pre-deployment agent validation\n",
    "Before registering and deploying the agent, perform pre-deployment checks using the [mlflow.models.predict()](https://mlflow.org/docs/latest/python_api/mlflow.models.html#mlflow.models.predict) API. See Databricks documentation ([AWS](https://docs.databricks.com/en/machine-learning/model-serving/model-serving-debug.html#validate-inputs) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/machine-learning/model-serving/model-serving-debug#before-model-deployment-validation-checks))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0aba434a-d6b5-4169-90b0-39b6557a5c6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "    input_data=input_example,\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53dcfac4-0816-4f74-bee6-559740a35235",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the model to Unity Catalog\n",
    "\n",
    "Update the `catalog`, `schema`, and `model_name` below to register the MLflow model to Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d10d68c-eaba-432b-a318-333774a999f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "catalog = \"\"\n",
    "schema = \"\"\n",
    "model_name = \"\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3c48cf1-9901-4764-be98-99092ac4142d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deploy the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "944439bd-53a5-4f8b-a2b2-0cad24b4e397",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "agents.deploy(UC_MODEL_NAME, uc_registered_model_info.version, tags={\"endpointSource\": \"docs\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c01c102-7010-487c-8a02-46f8e4883748",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next steps\n",
    "\n",
    "After your agent is deployed, you can chat with it in AI playground to perform additional checks, share it with SMEs in your organization for feedback, or embed it in a production application. See Databricks documentation ([AWS](https://docs.databricks.com/en/generative-ai/deploy-agent.html) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/deploy-agent))."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "4. langgraph-multiagent-genie",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
