{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24bc957b-5d00-4f93-b6a4-400af715c3b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "https://docs.databricks.com/aws/en/generative-ai/tutorials/external-models-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bead5a17-beb5-46c8-b516-7d0da9a03089",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Requirements\n",
    "- Databricks Runtime 13.0 ML or above.\n",
    "- MLflow 2.9 or above.\n",
    "- OpenAI API keys.\n",
    "- Install the Databricks CLI version 0.205 or above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c66f7795-c848-4c23-9b6e-e1eac3781946",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "openai_api_key = \"sk-yourApiKey\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04d17bc7-13dc-4532-91d9-fb4490c7f9d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Step 2: Create and manage an external model endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e293371f-c64b-4912-9d32-dd551c6c9716",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The following code snippet creates a completions endpoint for OpenAI gpt-3.5-turbo-instruct, as specified in the served_entities section of the configuration. For your endpoint, be sure to populate the name and openai_api_key with your unique values for each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f94fe00-c8fa-4c94-92f1-617649914c2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.deployments\n",
    "\n",
    "client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "client.create_endpoint(\n",
    "    name=\"openai-completions-endpoint\",\n",
    "    config={\n",
    "        \"served_entities\": [{\n",
    "            \"name\": \"openai-completions\",\n",
    "            \"external_model\": {\n",
    "                \"name\": \"gpt-3.5-turbo-instruct\",\n",
    "                \"provider\": \"openai\",\n",
    "                \"task\": \"llm/v1/completions\",\n",
    "                \"openai_config\": {\n",
    "                    \"openai_api_key\": \"{{secrets/my_openai_secret_scope/openai_api_key}}\"\n",
    "                }\n",
    "            }\n",
    "        }]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e45f2ba-723b-4423-b4c5-dd3db0f4bdaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The following code snippet shows how you can provide your OpenAI API key as a plaintext string for an alternative way to create the same completions endpoint as above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3576548e-74d0-4498-956b-54e413fd2952",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import mlflow.deployments\n",
    "\n",
    "# client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "# client.create_endpoint(\n",
    "#     name=\"openai-completions-endpoint\",\n",
    "#     config={\n",
    "#         \"served_entities\": [{\n",
    "#             \"name\": \"openai-completions\",\n",
    "#             \"external_model\": {\n",
    "#                 \"name\": \"gpt-3.5-turbo-instruct\",\n",
    "#                 \"provider\": \"openai\",\n",
    "#                 \"task\": \"llm/v1/completions\",\n",
    "#                 \"openai_config\": {\n",
    "#                     \"openai_api_key_plaintext\": \"sk-yourApiKey\"\n",
    "#                 }\n",
    "#             }\n",
    "#         }]\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c229846-5928-4818-84ce-e412301eed1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "If you are using Azure OpenAI, you can also specify the Azure OpenAI deployment name, endpoint URL, and API version in the openai_config section of the configuration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31f33534-1e5f-400b-84f6-db9a4bc36d55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# client.create_endpoint(\n",
    "#     name=\"openai-completions-endpoint\",\n",
    "#     config={\n",
    "#         \"served_entities\": [\n",
    "#           {\n",
    "#             \"name\": \"openai-completions\",\n",
    "#             \"external_model\": {\n",
    "#                 \"name\": \"gpt-3.5-turbo-instruct\",\n",
    "#                 \"provider\": \"openai\",\n",
    "#                 \"task\": \"llm/v1/completions\",\n",
    "#                 \"openai_config\": {\n",
    "#                     \"openai_api_type\": \"azure\",\n",
    "#                     \"openai_api_key\": \"{{secrets/my_openai_secret_scope/openai_api_key}}\",\n",
    "#                     \"openai_api_base\": \"https://my-azure-openai-endpoint.openai.azure.com\",\n",
    "#                     \"openai_deployment_name\": \"my-gpt-35-turbo-deployment\",\n",
    "#                     \"openai_api_version\": \"2023-05-15\"\n",
    "#                 },\n",
    "#             },\n",
    "#           }\n",
    "#         ],\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6eec0247-09fc-41b2-995c-c7d016ef107f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To update an endpoint, use update_endpoint(). The following code snippet demonstrates how to update an endpoint's rate limits to 20 calls per minute per user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38b085e7-1453-44d9-9ab6-4d8c3d9db672",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# client.update_endpoint(\n",
    "#     endpoint=\"openai-completions-endpoint\",\n",
    "#     config={\n",
    "#         \"rate_limits\": [\n",
    "#             {\n",
    "#                 \"key\": \"user\",\n",
    "#                 \"renewal_period\": \"minute\",\n",
    "#                 \"calls\": 20\n",
    "#             }\n",
    "#         ],\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc239d78-d9b6-41a3-a05e-668c2810fa9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 3: Send requests to an external model endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ccb3a879-fecf-463f-876c-027ea0918751",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You can send chat, completions, and embeddings requests to an external model endpoint using the MLflow Deployments SDK's predict() method.\n",
    "\n",
    "The following sends a request to gpt-3.5-turbo-instruct hosted by OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6a5904b-a528-4eb2-b574-c6f9c5f44558",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "completions_response = client.predict(\n",
    "    endpoint=\"openai-completions-endpoint\",\n",
    "    inputs={\n",
    "        \"prompt\": \"What is the capital of France?\",\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_tokens\": 10,\n",
    "        \"n\": 2\n",
    "    }\n",
    ")\n",
    "# completions_response == {\n",
    "#     \"id\": \"cmpl-8QW0hdtUesKmhB3a1Vel6X25j2MDJ\",\n",
    "#     \"object\": \"text_completion\",\n",
    "#     \"created\": 1701330267,\n",
    "#     \"model\": \"gpt-3.5-turbo-instruct\",\n",
    "#     \"choices\": [\n",
    "#         {\n",
    "#             \"text\": \"The capital of France is Paris.\",\n",
    "#             \"index\": 0,\n",
    "#             \"finish_reason\": \"stop\",\n",
    "#             \"logprobs\": None\n",
    "#         },\n",
    "#         {\n",
    "#             \"text\": \"Paris is the capital of France\",\n",
    "#             \"index\": 1,\n",
    "#             \"finish_reason\": \"stop\",\n",
    "#             \"logprobs\": None\n",
    "#         },\n",
    "#     ],\n",
    "#     \"usage\": {\n",
    "#         \"prompt_tokens\": 7,\n",
    "#         \"completion_tokens\": 16,\n",
    "#         \"total_tokens\": 23\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe1ab2fa-d117-4f6b-9627-83037066a51f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "completions_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c412cda6-21d7-4ea4-b26a-12a3d2291631",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 4: Compare models from a different provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3cc0c5e4-f8a5-41d9-aa78-e7b131ea76a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Model serving supports many external model providers including Open AI, Anthropic, Cohere, Amazon Bedrock, Google Cloud Vertex AI, and more. You can compare LLMs across providers, helping you optimize the accuracy, speed, and cost of your applications using the AI Playground.\n",
    "\n",
    "The following example creates an endpoint for Anthropic claude-2 and compares its response to a question that uses OpenAI gpt-3.5-turbo-instruct. Both responses have the same standard format, which makes them easy to compare.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12c26939-e094-49cc-b386-7aadb1bfef98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create an endpoint for Anthropic claude-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf85ef50-af78-4ab5-8f3a-5a3a8241809c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from databricks.sdk import WorkspaceClient\n",
    "\n",
    "# # Initialize the Databricks client\n",
    "# client = WorkspaceClient()\n",
    "\n",
    "# # Create a secret scope\n",
    "# client.secrets.create_scope(scope=\"my_anthropic_secret_scope\")\n",
    "\n",
    "# # Add a secret to the scope\n",
    "# client.secrets.put_secret(\n",
    "#     scope=\"my_anthropic_secret_scope\",\n",
    "#     key=\"anthropic_api_key\",\n",
    "#     string_value=\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de2624fb-2977-4a38-98e3-b6b102e2fdd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.deployments\n",
    "\n",
    "client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "\n",
    "client.create_endpoint(\n",
    "    name=\"anthropic-completions-endpoint\",\n",
    "    config={\n",
    "        \"served_entities\": [\n",
    "            {\n",
    "                \"name\": \"claude-completions\",\n",
    "                \"external_model\": {\n",
    "                    \"name\": \"claude-2\",\n",
    "                    \"provider\": \"anthropic\",\n",
    "                    \"task\": \"llm/v1/completions\",\n",
    "                    \"anthropic_config\": {\n",
    "                        \"anthropic_api_key\": \"{{secrets/my_anthropic_secret_scope/anthropic_api_key}}\"\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef0cc947-5e7e-4258-813b-4f435925b09b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Compare the responses from each endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89289171-4136-4d4a-99b3-4cf355a4ebab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "openai_response = client.predict(\n",
    "    endpoint=\"openai-completions-endpoint\",\n",
    "    inputs={\n",
    "        \"prompt\": \"How is Pi calculated? Be very concise.\"\n",
    "    }\n",
    ")\n",
    "# anthropic_response = client.predict(\n",
    "#     endpoint=\"anthropic-completions-endpoint\",\n",
    "#     inputs={\n",
    "#         \"prompt\": \"How is Pi calculated? Be very concise.\"\n",
    "#     }\n",
    "# )\n",
    "openai_response[\"choices\"] == [\n",
    "    {\n",
    "        \"text\": \"Pi is calculated by dividing the circumference of a circle by its diameter.\"\n",
    "                \" This constant ratio of 3.14159... is then used to represent the relationship\"\n",
    "                \" between a circle's circumference and its diameter, regardless of the size of the\"\n",
    "                \" circle.\",\n",
    "        \"index\": 0,\n",
    "        \"finish_reason\": \"stop\",\n",
    "        \"logprobs\": None\n",
    "    }\n",
    "]\n",
    "# anthropic_response[\"choices\"] == [\n",
    "#     {\n",
    "#         \"text\": \"Pi is calculated by approximating the ratio of a circle's circumference to\"\n",
    "#                 \" its diameter. Common approximation methods include infinite series, infinite\"\n",
    "#                 \" products, and computing the perimeters of polygons with more and more sides\"\n",
    "#                 \" inscribed in or around a circle.\",\n",
    "#         \"index\": 0,\n",
    "#         \"finish_reason\": \"stop\",\n",
    "#         \"logprobs\": None\n",
    "#     }\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a25273e4-322b-4067-9c4f-68b1b8a6c944",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "dbe_41a50460-c90b-4840-9288-afcb847395d5",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "OpenAI_External Models",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
