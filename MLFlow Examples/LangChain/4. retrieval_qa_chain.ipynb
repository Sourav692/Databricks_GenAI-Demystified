{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee7b6a71-e14a-4999-a78c-c23a07bd07fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install -qq langchain\n",
    "!pip install -qq langchain_core\n",
    "!pip install -qq langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08b4bf47-251b-45aa-99a9-0d8464746b4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install -qq langchain_openai\n",
    "!pip install -qq faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31a6ddd8-0167-400a-a54b-06a7d66a2b3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = dbutils.secrets.get(scope=\"sourav_secret_scope\", key=\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6895f850-e6aa-4ffc-a076-c3e68a2895e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "467fcfe1-a295-46f8-b0cf-96d342402528",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# data_path = \"/\".join(dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get().split(\"/\")[:-1])+\"/tests\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa2e9183-bdf3-4b0d-a047-4e6058a1fff8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    persist_dir = os.path.join(temp_dir, \"faiss_index\")\n",
    "\n",
    "    # Create the vector db, persist the db to a local fs folder\n",
    "    loader = TextLoader(\"./tests/state_of_the_union.txt\")\n",
    "    documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "    db.save_local(persist_dir)\n",
    "\n",
    "    # Create the RetrievalQA chain\n",
    "    # retrievalQA = RetrievalQA.from_llm(llm=OpenAI(allow_dangerous_deserialization=True), chain_type=\"stuff\", retriever=db.as_retriever())\n",
    "\n",
    "    retrieval_qa = RetrievalQA.from_chain_type(llm=OpenAI(allow_dangerous_deserialization=True), chain_type=\"stuff\", retriever=db.as_retriever())\n",
    "\n",
    "\n",
    "    # Log the retrievalQA chain\n",
    "    def load_retriever(persist_directory):\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        vectorstore = FAISS.load_local(persist_directory, embeddings,allow_dangerous_deserialization=True)\n",
    "        return vectorstore.as_retriever()\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        logged_model = mlflow.langchain.log_model(\n",
    "            retrievalQA,\n",
    "            artifact_path=\"retrieval_qa\",\n",
    "            registered_model_name=\"RetrievalQA_model\", \n",
    "            loader_fn=load_retriever,\n",
    "            persist_dir=persist_dir,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "725a7b8a-1ad9-4913-87a7-7ba71149ec94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "f\"runs:/{ run.info.run_id }/retrieval_qa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e2ee43f-89c3-40cc-8a0e-d0f4540b303f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logged_model.model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5eba4279-f6c4-4a81-99c4-e2c71220c50f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the retriever chain\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model.model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c5b7e89-d832-43f0-aa84-b7f7dd426efa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(loaded_model.predict([{\"query\": \"What did the president say about Ketanji Brown Jackson\"}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfbcebf3-7424-4179-adee-4d9aad98521a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "dbe_41a50460-c90b-4840-9288-afcb847395d5",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "4. retrieval_qa_chain",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
